{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"d8JAmEUyj9De"},"outputs":[],"source":["# ATENCIÓN!! Modificar ruta relativa a la práctica si es distinta (drive_root)\n","mount='/content/gdrive'\n","drive_root = mount + \"/My Drive/TFM\"\n","\n","try:\n","  from google.colab import drive\n","  IN_COLAB=True\n","except:\n","  IN_COLAB=False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24921,"status":"ok","timestamp":1696847290392,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"},"user_tz":-120},"id":"DrEo9QnxkAne","outputId":"65acfda3-ff84-466b-8ca5-5fc748388519"},"outputs":[{"output_type":"stream","name":"stdout","text":["We're running Colab\n","Colab: mounting Google drive on  /content/gdrive\n","Mounted at /content/gdrive\n","\n","Colab: making sure  /content/gdrive/My Drive/TFM  exists.\n","\n","Colab: Changing directory to  /content/gdrive/My Drive/TFM\n","/content/gdrive/My Drive/TFM\n","Archivos en el directorio: \n","['og_multi_car_racing', 'multi_car_racing', 'MCR_TFM.ipynb', 'Atari_TFM.ipynb', 'Entrenamientos antiguos sin logs', '.ipynb_checkpoints', 'policy_log_eval', 'Entrenamientos_log_no_eval', 'policy_new_log_eval', 'policy_eval.zip', '=2.13', 'policy_new2_log_eval', 'policy2_log_eval', 'TFM_pettingzoo_gym_cap.ipynb', 'TFM_new_pettingzoo_gym_cap.ipynb']\n"]}],"source":["# Switch to the directory on the Google Drive that you want to use\n","import os\n","if IN_COLAB:\n","  print(\"We're running Colab\")\n","\n","  if IN_COLAB:\n","    # Mount the Google Drive at mount\n","    print(\"Colab: mounting Google drive on \", mount)\n","\n","    drive.mount(mount)\n","\n","    # Create drive_root if it doesn't exist\n","    create_drive_root = True\n","    if create_drive_root:\n","      print(\"\\nColab: making sure \", drive_root, \" exists.\")\n","      os.makedirs(drive_root, exist_ok=True)\n","\n","    # Change to the directory\n","    print(\"\\nColab: Changing directory to \", drive_root)\n","    %cd $drive_root\n","# Verify we're in the correct working directory\n","%pwd\n","print(\"Archivos en el directorio: \")\n","print(os.listdir())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":235960,"status":"ok","timestamp":1696847526340,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"},"user_tz":-120},"id":"xAZDg478kEbs","outputId":"decdf620-93e7-478a-bf23-77a330b5ce62"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gym==0.17.3\n","  Downloading gym-0.17.3.tar.gz (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gym==0.17.3) (1.11.3)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.17.3) (1.23.5)\n","Collecting pyglet<=1.5.0,>=1.4.0 (from gym==0.17.3)\n","  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cloudpickle<1.7.0,>=1.2.0 (from gym==0.17.3)\n","  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (0.18.3)\n","Building wheels for collected packages: gym\n","  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.17.3-py3-none-any.whl size=1654617 sha256=f369a006742f1c711054c26c9e8918801aa0d743fc31f019acfaf09b04f210a9\n","  Stored in directory: /root/.cache/pip/wheels/af/4b/74/fcfc8238472c34d7f96508a63c962ff3ac9485a9a4137afd4e\n","Successfully built gym\n","Installing collected packages: pyglet, cloudpickle, gym\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 2.2.1\n","    Uninstalling cloudpickle-2.2.1:\n","      Successfully uninstalled cloudpickle-2.2.1\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.25.2\n","    Uninstalling gym-0.25.2:\n","      Successfully uninstalled gym-0.25.2\n","Successfully installed cloudpickle-1.6.0 gym-0.17.3 pyglet-1.5.0\n","Collecting git+https://github.com/Kojoley/atari-py.git\n","  Cloning https://github.com/Kojoley/atari-py.git to /tmp/pip-req-build-xygfyrln\n","  Running command git clone --filter=blob:none --quiet https://github.com/Kojoley/atari-py.git /tmp/pip-req-build-xygfyrln\n","  Resolved https://github.com/Kojoley/atari-py.git to commit 86a1e05c0a95e9e6233c3a413521fdb34ca8a089\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from atari-py==1.2.2) (1.23.5)\n","Building wheels for collected packages: atari-py\n","  Building wheel for atari-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for atari-py: filename=atari_py-1.2.2-cp310-cp310-linux_x86_64.whl size=4738736 sha256=1e75bee5ca20b941b96ca24aca3fc4ed319899a0da0435653913532b503655fe\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-_jshlloj/wheels/6c/9b/f1/8a80a63a233d6f4eb2e2ee8c7357f4875f21c3ffc7f2613f9f\n","Successfully built atari-py\n","Installing collected packages: atari-py\n","Successfully installed atari-py-1.2.2\n","Collecting keras-rl2==1.0.5\n","  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from keras-rl2==1.0.5) (2.13.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.59.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (3.9.0)\n","Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (2.13.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (16.0.6)\n","Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.16.0)\n","Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (2.13.0)\n","Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (2.13.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (2.3.0)\n","Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.15.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2==1.0.5) (0.34.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2==1.0.5) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (3.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (3.0.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->keras-rl2==1.0.5) (3.2.2)\n","Installing collected packages: keras-rl2\n","Successfully installed keras-rl2-1.0.5\n","Collecting tensorflow==2.8\n","  Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (1.6.3)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (23.5.26)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (3.9.0)\n","Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.8)\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (16.0.6)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (3.3.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (1.15.0)\n","Collecting tensorboard<2.9,>=2.8 (from tensorflow==2.8)\n","  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8)\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8)\n","  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (0.34.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (1.59.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.17.3)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8)\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.31.0)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8)\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8)\n","  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.0.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.2.2)\n","Installing collected packages: tf-estimator-nightly, tensorboard-plugin-wit, keras, tensorboard-data-server, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.13.1\n","    Uninstalling keras-2.13.1:\n","      Successfully uninstalled keras-2.13.1\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.1\n","    Uninstalling tensorboard-data-server-0.7.1:\n","      Successfully uninstalled tensorboard-data-server-0.7.1\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.0.0\n","    Uninstalling google-auth-oauthlib-1.0.0:\n","      Successfully uninstalled google-auth-oauthlib-1.0.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.13.0\n","    Uninstalling tensorboard-2.13.0:\n","      Successfully uninstalled tensorboard-2.13.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.13.0\n","    Uninstalling tensorflow-2.13.0:\n","      Successfully uninstalled tensorflow-2.13.0\n","Successfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n","Collecting gym-cap\n","  Downloading gym_cap-0.1.4.12-py3-none-any.whl (32 kB)\n","Requirement already satisfied: gym>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from gym-cap) (0.17.3)\n","Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from gym-cap) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gym>=0.16.0->gym-cap) (1.11.3)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.16.0->gym-cap) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.16.0->gym-cap) (1.6.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.16.0->gym-cap) (0.18.3)\n","Installing collected packages: gym-cap\n","Successfully installed gym-cap-0.1.4.12\n","Collecting pettingzoo[butterfly]\n","  Downloading pettingzoo-1.24.1-py3-none-any.whl (840 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.8/840.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo[butterfly]) (1.23.5)\n","Collecting gymnasium>=0.28.0 (from pettingzoo[butterfly])\n","  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pygame==2.3.0 (from pettingzoo[butterfly])\n","  Downloading pygame-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pymunk==6.2.0 (from pettingzoo[butterfly])\n","  Downloading pymunk-6.2.0.zip (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cffi>1.14.0 in /usr/local/lib/python3.10/dist-packages (from pymunk==6.2.0->pettingzoo[butterfly]) (1.16.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo[butterfly]) (1.6.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo[butterfly]) (4.5.0)\n","Collecting farama-notifications>=0.0.1 (from gymnasium>=0.28.0->pettingzoo[butterfly])\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>1.14.0->pymunk==6.2.0->pettingzoo[butterfly]) (2.21)\n","Building wheels for collected packages: pymunk\n","  Building wheel for pymunk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pymunk: filename=pymunk-6.2.0-cp310-cp310-linux_x86_64.whl size=801635 sha256=7f92d4692caadfd4dc8c2c137f0daad468b5505ccc81bae939337088c1134b51\n","  Stored in directory: /root/.cache/pip/wheels/2e/81/a2/f941a9ff417bb4020c37ae218fb7117d12d3fc019ea493d66f\n","Successfully built pymunk\n","Installing collected packages: farama-notifications, pygame, gymnasium, pymunk, pettingzoo\n","  Attempting uninstall: pygame\n","    Found existing installation: pygame 2.5.2\n","    Uninstalling pygame-2.5.2:\n","      Successfully uninstalled pygame-2.5.2\n","Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1 pettingzoo-1.24.1 pygame-2.3.0 pymunk-6.2.0\n"]}],"source":["if IN_COLAB:\n","  %pip install gym==0.17.3\n","  %pip install git+https://github.com/Kojoley/atari-py.git\n","  %pip install keras-rl2==1.0.5\n","  %pip install tensorflow==2.8\n","  %pip install gym-cap\n","  %pip install pettingzoo[butterfly]\n","else:\n","  %pip install gym==0.17.3\n","  %pip install git+https://github.com/Kojoley/atari-py.git\n","  %pip install pyglet==1.5.0\n","  %pip install h5py==3.1.0\n","  %pip install Pillow==9.5.0\n","  %pip install keras-rl2==1.0.5\n","  %pip install Keras==2.2.4\n","  %pip install tensorflow==2.5.3\n","  %pip install torch==2.0.1\n","  %pip install agents==1.4.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1696847526589,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"},"user_tz":-120},"id":"G8cw-IX3laE9","outputId":"3962b6f0-dd01-4e6e-c4b5-8f13ee541ccb"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'multi_car_racing' already exists and is not an empty directory.\n"]}],"source":["!git clone https://github.com/igilitschenski/multi_car_racing.git\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IqbMo3gK7vBG"},"outputs":[],"source":["!cd multi_car_racing\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7002,"status":"ok","timestamp":1696847533583,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"},"user_tz":-120},"id":"Jekec6f98b3A","outputId":"9618dce2-5474-467c-e470-a91c1995bd8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting swig\n","  Downloading swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: swig\n","Successfully installed swig-4.1.1\n"]}],"source":["!pip install swig"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65332,"status":"ok","timestamp":1696847598905,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"},"user_tz":-120},"id":"KKxRPBFx85k6","outputId":"0763f5e0-2237-458d-95b2-8eb45868d298"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting box2d\n","  Downloading Box2D-2.3.2.tar.gz (427 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.9/427.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: box2d\n","  Building wheel for box2d (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for box2d: filename=Box2D-2.3.2-cp310-cp310-linux_x86_64.whl size=2391309 sha256=d1c727d41bed86ec3846c22c97e1ca950e92f57ad602f5d54c9bd6f194f0ca9c\n","  Stored in directory: /root/.cache/pip/wheels/eb/cb/be/e663f3ce9aba6580611c0febaf7cd3cf7603f87047de2a52f9\n","Successfully built box2d\n","Installing collected packages: box2d\n","Successfully installed box2d-2.3.2\n"]}],"source":["!pip install box2d"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65226,"status":"ok","timestamp":1696847664082,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"},"user_tz":-120},"id":"ijp5V0i09MRF","outputId":"f8e1a4a0-0d2e-4050-e344-1e6563840fe6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting box2d-py\n","  Downloading box2d-py-2.3.8.tar.gz (374 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.5/374.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: box2d-py\n","  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for box2d-py: filename=box2d_py-2.3.8-cp310-cp310-linux_x86_64.whl size=2373077 sha256=931643998012a0e200d2dfdf77858a44073d5427496bee27e82f724462a6a541\n","  Stored in directory: /root/.cache/pip/wheels/47/01/d2/6a780da77ccb98b1d2facdd520a8d10838a03b590f6f8d50c0\n","Successfully built box2d-py\n","Installing collected packages: box2d-py\n","Successfully installed box2d-py-2.3.8\n"]}],"source":["!pip install box2d-py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31384,"status":"ok","timestamp":1696847695416,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"},"user_tz":-120},"id":"BwjugqI99g0I","outputId":"dd65b6af-30ef-4ff7-e82d-9357b2b2f96b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Obtaining file:///content/gdrive/My%20Drive/TFM/multi_car_racing\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: box2d-py~=2.3.5 in /usr/local/lib/python3.10/dist-packages (from gym-multi-car-racing==0.0.1) (2.3.8)\n","Collecting shapely~=1.7.0 (from gym-multi-car-racing==0.0.1)\n","  Downloading Shapely-1.7.1.tar.gz (383 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.2/383.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from gym-multi-car-racing==0.0.1) (1.23.5)\n","Requirement already satisfied: gym~=0.17.2 in /usr/local/lib/python3.10/dist-packages (from gym-multi-car-racing==0.0.1) (0.17.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gym~=0.17.2->gym-multi-car-racing==0.0.1) (1.11.3)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from gym~=0.17.2->gym-multi-car-racing==0.0.1) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym~=0.17.2->gym-multi-car-racing==0.0.1) (1.6.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym~=0.17.2->gym-multi-car-racing==0.0.1) (0.18.3)\n","Building wheels for collected packages: shapely\n","  Building wheel for shapely (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for shapely: filename=Shapely-1.7.1-cp310-cp310-linux_x86_64.whl size=997924 sha256=8cd39109c796adfd0d6c10b5b544527713d59dd049be2e63d334c207d509a936\n","  Stored in directory: /root/.cache/pip/wheels/2e/fa/97/c85f587c35afcaf4a81c481741d36592518d1e50445572f0d4\n","Successfully built shapely\n","Installing collected packages: shapely, gym-multi-car-racing\n","  Attempting uninstall: shapely\n","    Found existing installation: shapely 2.0.1\n","    Uninstalling shapely-2.0.1:\n","      Successfully uninstalled shapely-2.0.1\n","  Running setup.py develop for gym-multi-car-racing\n","Successfully installed gym-multi-car-racing-0.0.1 shapely-1.7.1\n"]}],"source":["!pip install -e multi_car_racing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11658,"status":"ok","timestamp":1696847707025,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"},"user_tz":-120},"id":"IrAvXzCW-Z3e","outputId":"25f720ea-55b2-4b31-ca3f-237fd3753796"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  freeglut3 libegl-dev libgl-dev libgl1-mesa-dev libgles-dev libgles1\n","  libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev libglx-dev\n","  libice-dev libopengl-dev libsm-dev libxt-dev\n","Suggested packages:\n","  libice-doc libsm-doc libxt-doc\n","The following NEW packages will be installed:\n","  freeglut3 freeglut3-dev libegl-dev libgl-dev libgl1-mesa-dev libgles-dev\n","  libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev\n","  libglx-dev libice-dev libopengl-dev libsm-dev libxt-dev\n","0 upgraded, 16 newly installed, 0 to remove and 18 not upgraded.\n","Need to get 1,261 kB of archives.\n","After this operation, 6,753 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n","Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.0.4-0ubuntu1~22.04.1 [6,510 B]\n","Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3-dev amd64 2.8.1-6 [126 kB]\n","Fetched 1,261 kB in 1s (1,841 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 16.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package freeglut3:amd64.\n","(Reading database ... 120875 files and directories currently installed.)\n","Preparing to unpack .../00-freeglut3_2.8.1-6_amd64.deb ...\n","Unpacking freeglut3:amd64 (2.8.1-6) ...\n","Selecting previously unselected package libglx-dev:amd64.\n","Preparing to unpack .../01-libglx-dev_1.4.0-1_amd64.deb ...\n","Unpacking libglx-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libgl-dev:amd64.\n","Preparing to unpack .../02-libgl-dev_1.4.0-1_amd64.deb ...\n","Unpacking libgl-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libglvnd-core-dev:amd64.\n","Preparing to unpack .../03-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n","Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libegl-dev:amd64.\n","Preparing to unpack .../04-libegl-dev_1.4.0-1_amd64.deb ...\n","Unpacking libegl-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libgles1:amd64.\n","Preparing to unpack .../05-libgles1_1.4.0-1_amd64.deb ...\n","Unpacking libgles1:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libgles-dev:amd64.\n","Preparing to unpack .../06-libgles-dev_1.4.0-1_amd64.deb ...\n","Unpacking libgles-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libopengl-dev:amd64.\n","Preparing to unpack .../07-libopengl-dev_1.4.0-1_amd64.deb ...\n","Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libglvnd-dev:amd64.\n","Preparing to unpack .../08-libglvnd-dev_1.4.0-1_amd64.deb ...\n","Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libgl1-mesa-dev:amd64.\n","Preparing to unpack .../09-libgl1-mesa-dev_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n","Unpacking libgl1-mesa-dev:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n","Selecting previously unselected package libglu1-mesa:amd64.\n","Preparing to unpack .../10-libglu1-mesa_9.0.2-1_amd64.deb ...\n","Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n","Selecting previously unselected package libglu1-mesa-dev:amd64.\n","Preparing to unpack .../11-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n","Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n","Selecting previously unselected package libice-dev:amd64.\n","Preparing to unpack .../12-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n","Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n","Selecting previously unselected package libsm-dev:amd64.\n","Preparing to unpack .../13-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n","Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n","Selecting previously unselected package libxt-dev:amd64.\n","Preparing to unpack .../14-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n","Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n","Selecting previously unselected package freeglut3-dev:amd64.\n","Preparing to unpack .../15-freeglut3-dev_2.8.1-6_amd64.deb ...\n","Unpacking freeglut3-dev:amd64 (2.8.1-6) ...\n","Setting up freeglut3:amd64 (2.8.1-6) ...\n","Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n","Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n","Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n","Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n","Setting up libgles1:amd64 (1.4.0-1) ...\n","Setting up libglx-dev:amd64 (1.4.0-1) ...\n","Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n","Setting up libopengl-dev:amd64 (1.4.0-1) ...\n","Setting up libgl-dev:amd64 (1.4.0-1) ...\n","Setting up libegl-dev:amd64 (1.4.0-1) ...\n","Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n","Setting up libgles-dev:amd64 (1.4.0-1) ...\n","Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n","Setting up libgl1-mesa-dev:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n","Setting up freeglut3-dev:amd64 (2.8.1-6) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n"]}],"source":["!sudo apt-get install freeglut3-dev"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25719,"status":"ok","timestamp":1696847732699,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"},"user_tz":-120},"id":"cgGdQ6n9EERW","outputId":"e40308c8-89ba-45e4-88c7-96d9b0fa1c54"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n","  xfonts-utils xserver-common\n","The following NEW packages will be installed:\n","  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n","  xfonts-utils xserver-common xvfb\n","0 upgraded, 9 newly installed, 0 to remove and 18 not upgraded.\n","Need to get 7,812 kB of archives.\n","After this operation, 11.9 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.1 [28.0 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.1 [863 kB]\n","Fetched 7,812 kB in 1s (7,646 kB/s)\n","Selecting previously unselected package libfontenc1:amd64.\n","(Reading database ... 121333 files and directories currently installed.)\n","Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n","Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Selecting previously unselected package libxfont2:amd64.\n","Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n","Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n","Selecting previously unselected package libxkbfile1:amd64.\n","Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n","Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n","Selecting previously unselected package x11-xkb-utils.\n","Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n","Unpacking x11-xkb-utils (7.7+5build4) ...\n","Selecting previously unselected package xfonts-encodings.\n","Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n","Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n","Selecting previously unselected package xfonts-utils.\n","Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n","Unpacking xfonts-utils (1:7.7+6build2) ...\n","Selecting previously unselected package xfonts-base.\n","Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n","Unpacking xfonts-base (1:1.0.5) ...\n","Selecting previously unselected package xserver-common.\n","Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.1_all.deb ...\n","Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.1) ...\n","Selecting previously unselected package xvfb.\n","Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.1_amd64.deb ...\n","Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.1) ...\n","Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n","Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n","Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n","Setting up x11-xkb-utils (7.7+5build4) ...\n","Setting up xfonts-utils (1:7.7+6build2) ...\n","Setting up xfonts-base (1:1.0.5) ...\n","Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.1) ...\n","Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","Collecting pyvirtualdisplay\n","  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n","Installing collected packages: pyvirtualdisplay\n","Successfully installed pyvirtualdisplay-3.0\n","Collecting piglet\n","  Downloading piglet-1.0.0-py2.py3-none-any.whl (2.2 kB)\n","Collecting piglet-templates (from piglet)\n","  Downloading piglet_templates-1.3.0-py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.5/67.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from piglet-templates->piglet) (3.1.1)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from piglet-templates->piglet) (23.1.0)\n","Requirement already satisfied: astunparse in /usr/local/lib/python3.10/dist-packages (from piglet-templates->piglet) (1.6.3)\n","Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from piglet-templates->piglet) (2.1.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse->piglet-templates->piglet) (0.41.2)\n","Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from astunparse->piglet-templates->piglet) (1.16.0)\n","Installing collected packages: piglet-templates, piglet\n","Successfully installed piglet-1.0.0 piglet-templates-1.3.0\n"]}],"source":["!apt install xvfb -y\n","!pip install pyvirtualdisplay\n","!pip install piglet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21004,"status":"ok","timestamp":1696847753693,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"},"user_tz":-120},"id":"5OaWkBSmhm6R","outputId":"7c935ad6-456f-4af6-945f-7470876a7706"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting supersuit\n","  Downloading SuperSuit-3.9.0-py3-none-any.whl (49 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from supersuit) (1.23.5)\n","Requirement already satisfied: gymnasium>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from supersuit) (0.29.1)\n","Collecting tinyscaler>=1.2.6 (from supersuit)\n","  Downloading tinyscaler-1.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (517 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.1/517.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->supersuit) (1.6.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->supersuit) (4.5.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->supersuit) (0.0.4)\n","Installing collected packages: tinyscaler, supersuit\n","Successfully installed supersuit-3.9.0 tinyscaler-1.2.7\n","Collecting stable_baselines3\n","  Downloading stable_baselines3-2.1.0-py3-none-any.whl (178 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (0.29.1)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.23.5)\n","Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.0.1+cu118)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.6.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.5.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.7.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.5.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (0.0.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.12.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->stable_baselines3) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->stable_baselines3) (17.0.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (0.12.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (4.43.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable_baselines3) (1.3.0)\n","Installing collected packages: stable_baselines3\n","Successfully installed stable_baselines3-2.1.0\n"]}],"source":["!pip install supersuit\n","!pip install stable_baselines3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7673,"status":"ok","timestamp":1696847761318,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"},"user_tz":-120},"id":"thmOvcHdjKHw","outputId":"d2688492-3add-42e2-8752-16f424d1f32f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting shimmy>=0.2.1\n","  Downloading Shimmy-1.2.1-py3-none-any.whl (37 kB)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from shimmy>=0.2.1) (1.23.5)\n","Requirement already satisfied: gymnasium>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from shimmy>=0.2.1) (0.29.1)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.27.0->shimmy>=0.2.1) (1.6.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.27.0->shimmy>=0.2.1) (4.5.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.27.0->shimmy>=0.2.1) (0.0.4)\n","Installing collected packages: shimmy\n","Successfully installed shimmy-1.2.1\n"]}],"source":["!pip install 'shimmy>=0.2.1'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25553,"status":"ok","timestamp":1696847786825,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"},"user_tz":-120},"id":"k0iVvep_spQz","outputId":"e28087a2-7976-4091-ab97-91252aa6ebad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tf-agents-nightly\n","  Downloading tf_agents_nightly-0.18.0.dev20231008-py3-none-any.whl (1.4 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.4 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents-nightly) (1.4.0)\n","Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents-nightly) (1.6.0)\n","Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents-nightly) (0.5.0)\n","Requirement already satisfied: gym<=0.23.0,>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents-nightly) (0.17.3)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents-nightly) (1.23.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tf-agents-nightly) (9.4.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents-nightly) (1.16.0)\n","Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents-nightly) (3.20.3)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents-nightly) (1.15.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents-nightly) (4.5.0)\n","Collecting pygame==2.1.3 (from tf-agents-nightly)\n","  Downloading pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tfp-nightly (from tf-agents-nightly)\n","  Downloading tfp_nightly-0.23.0.dev20231009-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents-nightly) (1.11.3)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents-nightly) (1.5.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tfp-nightly->tf-agents-nightly) (4.4.2)\n","Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tfp-nightly->tf-agents-nightly) (0.4.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tfp-nightly->tf-agents-nightly) (0.1.8)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<=0.23.0,>=0.17.0->tf-agents-nightly) (0.18.3)\n","Installing collected packages: tfp-nightly, pygame, tf-agents-nightly\n","  Attempting uninstall: pygame\n","    Found existing installation: pygame 2.3.0\n","    Uninstalling pygame-2.3.0:\n","      Successfully uninstalled pygame-2.3.0\n","Successfully installed pygame-2.1.3 tf-agents-nightly-0.18.0.dev20231008 tfp-nightly-0.23.0.dev20231009\n"]}],"source":["!pip install tf-agents-nightly"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8512,"status":"ok","timestamp":1696847795290,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"},"user_tz":-120},"id":"UlXxViz9tdvH","outputId":"5ae36c53-14c9-4dfd-9819-79a0c3e1966b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 2.8.0\n","Uninstalling tensorflow-2.8.0:\n","  Would remove:\n","    /usr/local/bin/estimator_ckpt_converter\n","    /usr/local/bin/import_pb_to_tensorboard\n","    /usr/local/bin/saved_model_cli\n","    /usr/local/bin/tensorboard\n","    /usr/local/bin/tf_upgrade_v2\n","    /usr/local/bin/tflite_convert\n","    /usr/local/bin/toco\n","    /usr/local/bin/toco_from_protos\n","    /usr/local/lib/python3.10/dist-packages/tensorflow-2.8.0.dist-info/*\n","    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n","Proceed (Y/n)? Y\n","  Successfully uninstalled tensorflow-2.8.0\n"]}],"source":["!pip uninstall tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dsWlVQ6MtKLj"},"outputs":[],"source":["!pip install tensorflow>=2.13"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10478,"status":"ok","timestamp":1696847855375,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"},"user_tz":-120},"id":"wE5AiVtFtZDc","outputId":"1457e147-cced-4b4d-b9a2-f20faa74e704"},"outputs":[{"output_type":"stream","name":"stdout","text":["Name: tensorflow\n","Version: 2.14.0\n","Summary: TensorFlow is an open source machine learning framework for everyone.\n","Home-page: https://www.tensorflow.org/\n","Author: Google Inc.\n","Author-email: packages@tensorflow.org\n","License: Apache 2.0\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n","Required-by: dopamine-rl, keras-rl2\n"]}],"source":["!pip show tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11597,"status":"ok","timestamp":1696847866923,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"},"user_tz":-120},"id":"GnLzCLnICYCz","outputId":"d4eb3f9f-0cf1-4060-d70b-20a7fb687402"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pettingzoo[butterfly] in /usr/local/lib/python3.10/dist-packages (1.24.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo[butterfly]) (1.23.5)\n","Requirement already satisfied: gymnasium>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo[butterfly]) (0.29.1)\n","Collecting pygame==2.3.0 (from pettingzoo[butterfly])\n","  Using cached pygame-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\n","Requirement already satisfied: pymunk==6.2.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo[butterfly]) (6.2.0)\n","Requirement already satisfied: cffi>1.14.0 in /usr/local/lib/python3.10/dist-packages (from pymunk==6.2.0->pettingzoo[butterfly]) (1.16.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo[butterfly]) (1.6.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo[butterfly]) (4.5.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo[butterfly]) (0.0.4)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>1.14.0->pymunk==6.2.0->pettingzoo[butterfly]) (2.21)\n","Installing collected packages: pygame\n","  Attempting uninstall: pygame\n","    Found existing installation: pygame 2.1.3\n","    Uninstalling pygame-2.1.3:\n","      Successfully uninstalled pygame-2.1.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-agents-nightly 0.18.0.dev20231008 requires pygame==2.1.3, but you have pygame 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pygame-2.3.0\n"]}],"source":["!pip install pettingzoo[butterfly]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JpA_YhKzCeC2"},"outputs":[],"source":["############################# Código para entrenar KAZ"]},{"cell_type":"code","source":["from stable_baselines3.ppo import MlpPolicy\n","from stable_baselines3 import PPO\n","from pettingzoo.butterfly import knights_archers_zombies_v10\n","import supersuit as ss\n","from stable_baselines3.common.monitor import Monitor"],"metadata":{"id":"Tnz3fJDA33w8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6-kdhb3CI5VC","executionInfo":{"status":"ok","timestamp":1696848222648,"user_tz":-120,"elapsed":244,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"}},"outputId":"e4641c80-aa3f-4f1d-e4d0-20372d35c8fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["drive  gdrive  sample_data\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/TFM"],"metadata":{"id":"04CbnRTvI9L2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696848224082,"user_tz":-120,"elapsed":319,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"}},"outputId":"7e3b8b24-a1bb-49f2-e4da-e8287d01683e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/TFM\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUEH8254I_kb","executionInfo":{"status":"ok","timestamp":1696848225257,"user_tz":-120,"elapsed":13,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"}},"outputId":"00564d52-42b1-49fd-b614-1e041a847e34"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'=2.13'\t\t\t\t     policy3_log_eval\n"," Atari_TFM.ipynb\t\t     policy_eval.zip\n","'Entrenamientos antiguos sin logs'   policy_log_eval\n"," Entrenamientos_log_no_eval\t     policy_new2_log_eval\n"," MCR_TFM.ipynb\t\t\t     policy_new_log_eval\n"," multi_car_racing\t\t     TFM_new_pettingzoo_gym_cap.ipynb\n"," og_multi_car_racing\t\t     TFM_pettingzoo_gym_cap.ipynb\n"," policy2_log_eval\n"]}]},{"cell_type":"code","source":["env = knights_archers_zombies_v10.parallel_env(render_mode=\"rgb_array\")\n","\n","# #---------------------------------\n","# log_dir = \"./policy_log\"\n","# os.makedirs(log_dir, exist_ok=True)\n","# env = Monitor(env, log_dir)\n","# #---------------------------------\n","# env = ss.color_reduction_v0(env, mode='B')\n","env = ss.black_death_v3(env)\n","env = ss.resize_v1(env, x_size=84, y_size=84)\n","env = ss.frame_stack_v1(env, 3)\n","env = ss.pettingzoo_env_to_vec_env_v1(env)\n","env = ss.concat_vec_envs_v1(env, 8, num_cpus=4, base_class='stable_baselines3')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2HubK-2G3_vH","executionInfo":{"status":"ok","timestamp":1696848228893,"user_tz":-120,"elapsed":1074,"user":{"displayName":"Víctor Manuel Arroyo Martín","userId":"10424599158381870205"}},"outputId":"1f029f27-b274-4759-a51f-ad82764a8dd5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pettingzoo/utils/conversions.py:252: UserWarning: The base environment `knights_archers_zombies_v10` does not have a `render_mode` defined.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/pettingzoo/utils/conversions.py:132: UserWarning: The base environment `aec_observation_lambda<knights_archers_zombies_v10>` does not have a `render_mode` defined.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from stable_baselines3.common.callbacks import EvalCallback\n","eval_callback = EvalCallback(env, best_model_save_path=\"./policy_log_eval/\",\n","                             log_path=\"./policy_log_eval/\", eval_freq=500,\n","                             deterministic=True, render=False)"],"metadata":{"id":"foI4bTFGbQo1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from stable_baselines3.common.logger import configure\n","\n","tmp_path = \"./policy_log_eval/\"\n","# set up logger\n","new_logger = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n","\n","model = PPO(MlpPolicy, env, verbose=3, gamma=0.95, n_steps=256, ent_coef=0.0905168, learning_rate=0.00062211, vf_coef=0.042202, max_grad_norm=0.9, gae_lambda=0.99, n_epochs=5, clip_range=0.3, batch_size=256)\n","# model.set_logger()\n","model.set_logger(new_logger)\n","model.learn(total_timesteps=5000000,callback=eval_callback)\n","model.save(\"policy_eval\")"],"metadata":{"id":"ib9VPIVgec47"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from stable_baselines3.common.callbacks import EvalCallback\n","eval_callback = EvalCallback(env, best_model_save_path=\"./policy2_log_eval/\",\n","                             log_path=\"./policy2_log_eval/\", eval_freq=500,\n","                             deterministic=True, render=False)"],"metadata":{"id":"H0lKH0t2kIP9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from stable_baselines3.common.logger import configure\n","\n","tmp_path = \"./policy2_log_eval/\"\n","# set up logger\n","new_logger = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n","\n","model = PPO.load(\"policy_log_eval/best_model\")\n","model.set_env(env)\n","model.set_parameters(\"policy_log_eval/best_model\")\n","# model.set_logger()\n","model.set_logger(new_logger)\n","model.learn(total_timesteps=5000000,callback=eval_callback)\n","model.save(\"policy2_eval\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F9i2kMahkL8M","outputId":"3451650d-5452-4956-d60b-1ce63ac9536d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Logging to ./policy2_log_eval/\n","-----------------------------\n","| time/              |      |\n","|    fps             | 445  |\n","|    iterations      | 1    |\n","|    time_elapsed    | 18   |\n","|    total_timesteps | 8192 |\n","-----------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n","|    fps             | 364     |\n","|    iterations      | 157     |\n","|    time_elapsed    | 3531    |\n","|    total_timesteps | 1286144 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 364         |\n","|    iterations           | 158         |\n","|    time_elapsed         | 3547        |\n","|    total_timesteps      | 1294336     |\n","| train/                  |             |\n","|    approx_kl            | 0.013138654 |\n","|    clip_fraction        | 0.044       |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.283       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.171      |\n","|    n_updates            | 2335        |\n","|    policy_gradient_loss | -0.0073     |\n","|    value_loss           | 0.0449      |\n","-----------------------------------------\n","Eval num_timesteps=1296000, episode_reward=0.80 +/- 1.17\n","Episode length: 180.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 180         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 1296000     |\n","| train/                  |             |\n","|    approx_kl            | 0.016521294 |\n","|    clip_fraction        | 0.0593      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.14        |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.159      |\n","|    n_updates            | 2340        |\n","|    policy_gradient_loss | -0.0082     |\n","|    value_loss           | 0.048       |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 364     |\n","|    iterations      | 159     |\n","|    time_elapsed    | 3575    |\n","|    total_timesteps | 1302528 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 364          |\n","|    iterations           | 160          |\n","|    time_elapsed         | 3591         |\n","|    total_timesteps      | 1310720      |\n","| train/                  |              |\n","|    approx_kl            | 0.0147461165 |\n","|    clip_fraction        | 0.0494       |\n","|    clip_range           | 0.3          |\n","|    entropy_loss         | -1.73        |\n","|    explained_variance   | 0.192        |\n","|    learning_rate        | 0.000622     |\n","|    loss                 | -0.149       |\n","|    n_updates            | 2345         |\n","|    policy_gradient_loss | -0.00642     |\n","|    value_loss           | 0.0476       |\n","------------------------------------------\n","Eval num_timesteps=1312000, episode_reward=1.00 +/- 1.55\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 1           |\n","| time/                   |             |\n","|    total_timesteps      | 1312000     |\n","| train/                  |             |\n","|    approx_kl            | 0.011520548 |\n","|    clip_fraction        | 0.0409      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.286       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.157      |\n","|    n_updates            | 2350        |\n","|    policy_gradient_loss | -0.00633    |\n","|    value_loss           | 0.049       |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 364     |\n","|    iterations      | 161     |\n","|    time_elapsed    | 3618    |\n","|    total_timesteps | 1318912 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 365         |\n","|    iterations           | 162         |\n","|    time_elapsed         | 3634        |\n","|    total_timesteps      | 1327104     |\n","| train/                  |             |\n","|    approx_kl            | 0.015763732 |\n","|    clip_fraction        | 0.0578      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.202       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.19       |\n","|    n_updates            | 2355        |\n","|    policy_gradient_loss | -0.00735    |\n","|    value_loss           | 0.0358      |\n","-----------------------------------------\n","Eval num_timesteps=1328000, episode_reward=0.20 +/- 0.40\n","Episode length: 172.00 +/- 16.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 172         |\n","|    mean_reward          | 0.2         |\n","| time/                   |             |\n","|    total_timesteps      | 1328000     |\n","| train/                  |             |\n","|    approx_kl            | 0.018199835 |\n","|    clip_fraction        | 0.0742      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.124       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.164      |\n","|    n_updates            | 2360        |\n","|    policy_gradient_loss | -0.0104     |\n","|    value_loss           | 0.0358      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 364     |\n","|    iterations      | 163     |\n","|    time_elapsed    | 3662    |\n","|    total_timesteps | 1335296 |\n","--------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 365        |\n","|    iterations           | 164        |\n","|    time_elapsed         | 3678       |\n","|    total_timesteps      | 1343488    |\n","| train/                  |            |\n","|    approx_kl            | 0.01023829 |\n","|    clip_fraction        | 0.0326     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.73      |\n","|    explained_variance   | 0.204      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.187     |\n","|    n_updates            | 2365       |\n","|    policy_gradient_loss | -0.00919   |\n","|    value_loss           | 0.0453     |\n","----------------------------------------\n","Eval num_timesteps=1344000, episode_reward=0.80 +/- 1.17\n","Episode length: 180.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 180         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 1344000     |\n","| train/                  |             |\n","|    approx_kl            | 0.012816871 |\n","|    clip_fraction        | 0.0472      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.179       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.182      |\n","|    n_updates            | 2370        |\n","|    policy_gradient_loss | -0.00735    |\n","|    value_loss           | 0.0428      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 364     |\n","|    iterations      | 165     |\n","|    time_elapsed    | 3707    |\n","|    total_timesteps | 1351680 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 365         |\n","|    iterations           | 166         |\n","|    time_elapsed         | 3722        |\n","|    total_timesteps      | 1359872     |\n","| train/                  |             |\n","|    approx_kl            | 0.015622349 |\n","|    clip_fraction        | 0.0669      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.215       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.189      |\n","|    n_updates            | 2375        |\n","|    policy_gradient_loss | -0.00703    |\n","|    value_loss           | 0.0405      |\n","-----------------------------------------\n","Eval num_timesteps=1360000, episode_reward=0.00 +/- 0.00\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0           |\n","| time/                   |             |\n","|    total_timesteps      | 1360000     |\n","| train/                  |             |\n","|    approx_kl            | 0.013830986 |\n","|    clip_fraction        | 0.044       |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.16        |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.15       |\n","|    n_updates            | 2380        |\n","|    policy_gradient_loss | -0.00491    |\n","|    value_loss           | 0.0389      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 365     |\n","|    iterations      | 167     |\n","|    time_elapsed    | 3748    |\n","|    total_timesteps | 1368064 |\n","--------------------------------\n","Eval num_timesteps=1376000, episode_reward=0.20 +/- 0.40\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0.2         |\n","| time/                   |             |\n","|    total_timesteps      | 1376000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014121415 |\n","|    clip_fraction        | 0.0404      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.0866      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.172      |\n","|    n_updates            | 2385        |\n","|    policy_gradient_loss | -0.01       |\n","|    value_loss           | 0.0295      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 364     |\n","|    iterations      | 168     |\n","|    time_elapsed    | 3774    |\n","|    total_timesteps | 1376256 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 365         |\n","|    iterations           | 169         |\n","|    time_elapsed         | 3789        |\n","|    total_timesteps      | 1384448     |\n","| train/                  |             |\n","|    approx_kl            | 0.018883836 |\n","|    clip_fraction        | 0.0677      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.115       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.19       |\n","|    n_updates            | 2390        |\n","|    policy_gradient_loss | -0.00959    |\n","|    value_loss           | 0.0457      |\n","-----------------------------------------\n","Eval num_timesteps=1392000, episode_reward=1.00 +/- 0.89\n","Episode length: 228.00 +/- 32.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 228         |\n","|    mean_reward          | 1           |\n","| time/                   |             |\n","|    total_timesteps      | 1392000     |\n","| train/                  |             |\n","|    approx_kl            | 0.013762346 |\n","|    clip_fraction        | 0.0407      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.0103      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.178      |\n","|    n_updates            | 2395        |\n","|    policy_gradient_loss | -0.00711    |\n","|    value_loss           | 0.0375      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 364     |\n","|    iterations      | 170     |\n","|    time_elapsed    | 3820    |\n","|    total_timesteps | 1392640 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 365         |\n","|    iterations           | 171         |\n","|    time_elapsed         | 3837        |\n","|    total_timesteps      | 1400832     |\n","| train/                  |             |\n","|    approx_kl            | 0.013461747 |\n","|    clip_fraction        | 0.0406      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.222       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.197      |\n","|    n_updates            | 2400        |\n","|    policy_gradient_loss | -0.00966    |\n","|    value_loss           | 0.0498      |\n","-----------------------------------------\n","Eval num_timesteps=1408000, episode_reward=0.60 +/- 0.80\n","Episode length: 204.00 +/- 40.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 204         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 1408000     |\n","| train/                  |             |\n","|    approx_kl            | 0.012613705 |\n","|    clip_fraction        | 0.0506      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.219       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.166      |\n","|    n_updates            | 2405        |\n","|    policy_gradient_loss | -0.00835    |\n","|    value_loss           | 0.0387      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 364     |\n","|    iterations      | 172     |\n","|    time_elapsed    | 3869    |\n","|    total_timesteps | 1409024 |\n","--------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 364       |\n","|    iterations           | 173       |\n","|    time_elapsed         | 3887      |\n","|    total_timesteps      | 1417216   |\n","| train/                  |           |\n","|    approx_kl            | 0.0139685 |\n","|    clip_fraction        | 0.0458    |\n","|    clip_range           | 0.3       |\n","|    entropy_loss         | -1.74     |\n","|    explained_variance   | 0.171     |\n","|    learning_rate        | 0.000622  |\n","|    loss                 | -0.185    |\n","|    n_updates            | 2410      |\n","|    policy_gradient_loss | -0.00918  |\n","|    value_loss           | 0.0404    |\n","---------------------------------------\n","Eval num_timesteps=1424000, episode_reward=1.60 +/- 2.06\n","Episode length: 256.00 +/- 16.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 256         |\n","|    mean_reward          | 1.6         |\n","| time/                   |             |\n","|    total_timesteps      | 1424000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014052922 |\n","|    clip_fraction        | 0.0514      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.239       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.192      |\n","|    n_updates            | 2415        |\n","|    policy_gradient_loss | -0.00827    |\n","|    value_loss           | 0.038       |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 363     |\n","|    iterations      | 174     |\n","|    time_elapsed    | 3917    |\n","|    total_timesteps | 1425408 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 364         |\n","|    iterations           | 175         |\n","|    time_elapsed         | 3935        |\n","|    total_timesteps      | 1433600     |\n","| train/                  |             |\n","|    approx_kl            | 0.015455862 |\n","|    clip_fraction        | 0.0482      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.199       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.176      |\n","|    n_updates            | 2420        |\n","|    policy_gradient_loss | -0.00981    |\n","|    value_loss           | 0.0385      |\n","-----------------------------------------\n","Eval num_timesteps=1440000, episode_reward=0.60 +/- 1.20\n","Episode length: 176.00 +/- 24.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 176         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 1440000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014935108 |\n","|    clip_fraction        | 0.0632      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.202       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.164      |\n","|    n_updates            | 2425        |\n","|    policy_gradient_loss | -0.00931    |\n","|    value_loss           | 0.0446      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 363     |\n","|    iterations      | 176     |\n","|    time_elapsed    | 3963    |\n","|    total_timesteps | 1441792 |\n","--------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 364        |\n","|    iterations           | 177        |\n","|    time_elapsed         | 3981       |\n","|    total_timesteps      | 1449984    |\n","| train/                  |            |\n","|    approx_kl            | 0.01459733 |\n","|    clip_fraction        | 0.0563     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.73      |\n","|    explained_variance   | 0.215      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.161     |\n","|    n_updates            | 2430       |\n","|    policy_gradient_loss | -0.00866   |\n","|    value_loss           | 0.037      |\n","----------------------------------------\n","Eval num_timesteps=1456000, episode_reward=0.00 +/- 0.00\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0           |\n","| time/                   |             |\n","|    total_timesteps      | 1456000     |\n","| train/                  |             |\n","|    approx_kl            | 0.018839447 |\n","|    clip_fraction        | 0.0571      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.166       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.166      |\n","|    n_updates            | 2435        |\n","|    policy_gradient_loss | -0.00805    |\n","|    value_loss           | 0.0385      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 363     |\n","|    iterations      | 178     |\n","|    time_elapsed    | 4007    |\n","|    total_timesteps | 1458176 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 364         |\n","|    iterations           | 179         |\n","|    time_elapsed         | 4024        |\n","|    total_timesteps      | 1466368     |\n","| train/                  |             |\n","|    approx_kl            | 0.014104206 |\n","|    clip_fraction        | 0.0566      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.129       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.177      |\n","|    n_updates            | 2440        |\n","|    policy_gradient_loss | -0.00809    |\n","|    value_loss           | 0.0358      |\n","-----------------------------------------\n","Eval num_timesteps=1472000, episode_reward=1.80 +/- 2.23\n","Episode length: 264.00 +/- 40.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 264        |\n","|    mean_reward          | 1.8        |\n","| time/                   |            |\n","|    total_timesteps      | 1472000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01235756 |\n","|    clip_fraction        | 0.0398     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.74      |\n","|    explained_variance   | 0.187      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.159     |\n","|    n_updates            | 2445       |\n","|    policy_gradient_loss | -0.00927   |\n","|    value_loss           | 0.0369     |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 363     |\n","|    iterations      | 180     |\n","|    time_elapsed    | 4059    |\n","|    total_timesteps | 1474560 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 363         |\n","|    iterations           | 181         |\n","|    time_elapsed         | 4075        |\n","|    total_timesteps      | 1482752     |\n","| train/                  |             |\n","|    approx_kl            | 0.011238143 |\n","|    clip_fraction        | 0.0358      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.0337      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.165      |\n","|    n_updates            | 2450        |\n","|    policy_gradient_loss | -0.00876    |\n","|    value_loss           | 0.0421      |\n","-----------------------------------------\n","Eval num_timesteps=1488000, episode_reward=1.60 +/- 1.85\n","Episode length: 288.00 +/- 32.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 288         |\n","|    mean_reward          | 1.6         |\n","| time/                   |             |\n","|    total_timesteps      | 1488000     |\n","| train/                  |             |\n","|    approx_kl            | 0.017411603 |\n","|    clip_fraction        | 0.0473      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.0961      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.142      |\n","|    n_updates            | 2455        |\n","|    policy_gradient_loss | -0.00874    |\n","|    value_loss           | 0.0448      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 182     |\n","|    time_elapsed    | 4109    |\n","|    total_timesteps | 1490944 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 363         |\n","|    iterations           | 183         |\n","|    time_elapsed         | 4128        |\n","|    total_timesteps      | 1499136     |\n","| train/                  |             |\n","|    approx_kl            | 0.013743201 |\n","|    clip_fraction        | 0.0463      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.154       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.195      |\n","|    n_updates            | 2460        |\n","|    policy_gradient_loss | -0.00946    |\n","|    value_loss           | 0.0354      |\n","-----------------------------------------\n","Eval num_timesteps=1504000, episode_reward=0.80 +/- 0.98\n","Episode length: 180.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 180         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 1504000     |\n","| train/                  |             |\n","|    approx_kl            | 0.020123955 |\n","|    clip_fraction        | 0.0504      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.151       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.175      |\n","|    n_updates            | 2465        |\n","|    policy_gradient_loss | -0.00805    |\n","|    value_loss           | 0.0468      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 184     |\n","|    time_elapsed    | 4154    |\n","|    total_timesteps | 1507328 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 363         |\n","|    iterations           | 185         |\n","|    time_elapsed         | 4172        |\n","|    total_timesteps      | 1515520     |\n","| train/                  |             |\n","|    approx_kl            | 0.013126718 |\n","|    clip_fraction        | 0.0446      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.179       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.172      |\n","|    n_updates            | 2470        |\n","|    policy_gradient_loss | -0.00421    |\n","|    value_loss           | 0.041       |\n","-----------------------------------------\n","Eval num_timesteps=1520000, episode_reward=0.60 +/- 0.80\n","Episode length: 196.00 +/- 16.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 196         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 1520000     |\n","| train/                  |             |\n","|    approx_kl            | 0.011457447 |\n","|    clip_fraction        | 0.0459      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.209       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.163      |\n","|    n_updates            | 2475        |\n","|    policy_gradient_loss | -0.00724    |\n","|    value_loss           | 0.0389      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 186     |\n","|    time_elapsed    | 4199    |\n","|    total_timesteps | 1523712 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 363         |\n","|    iterations           | 187         |\n","|    time_elapsed         | 4217        |\n","|    total_timesteps      | 1531904     |\n","| train/                  |             |\n","|    approx_kl            | 0.015879605 |\n","|    clip_fraction        | 0.0616      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.0804      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.171      |\n","|    n_updates            | 2480        |\n","|    policy_gradient_loss | -0.00892    |\n","|    value_loss           | 0.041       |\n","-----------------------------------------\n","Eval num_timesteps=1536000, episode_reward=0.00 +/- 0.00\n","Episode length: 172.00 +/- 16.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 172         |\n","|    mean_reward          | 0           |\n","| time/                   |             |\n","|    total_timesteps      | 1536000     |\n","| train/                  |             |\n","|    approx_kl            | 0.013812591 |\n","|    clip_fraction        | 0.0326      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.175       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.169      |\n","|    n_updates            | 2485        |\n","|    policy_gradient_loss | -0.00579    |\n","|    value_loss           | 0.0427      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 188     |\n","|    time_elapsed    | 4244    |\n","|    total_timesteps | 1540096 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 363         |\n","|    iterations           | 189         |\n","|    time_elapsed         | 4263        |\n","|    total_timesteps      | 1548288     |\n","| train/                  |             |\n","|    approx_kl            | 0.011574049 |\n","|    clip_fraction        | 0.0367      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.29        |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.16       |\n","|    n_updates            | 2490        |\n","|    policy_gradient_loss | -0.00895    |\n","|    value_loss           | 0.0431      |\n","-----------------------------------------\n","Eval num_timesteps=1552000, episode_reward=1.00 +/- 0.89\n","Episode length: 216.00 +/- 16.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 216         |\n","|    mean_reward          | 1           |\n","| time/                   |             |\n","|    total_timesteps      | 1552000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014120029 |\n","|    clip_fraction        | 0.0555      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.153       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.165      |\n","|    n_updates            | 2495        |\n","|    policy_gradient_loss | -0.00594    |\n","|    value_loss           | 0.0383      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 190     |\n","|    time_elapsed    | 4290    |\n","|    total_timesteps | 1556480 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 363         |\n","|    iterations           | 191         |\n","|    time_elapsed         | 4308        |\n","|    total_timesteps      | 1564672     |\n","| train/                  |             |\n","|    approx_kl            | 0.015639335 |\n","|    clip_fraction        | 0.0456      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.0605      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.172      |\n","|    n_updates            | 2500        |\n","|    policy_gradient_loss | -0.00774    |\n","|    value_loss           | 0.0423      |\n","-----------------------------------------\n","Eval num_timesteps=1568000, episode_reward=0.20 +/- 0.40\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0.2         |\n","| time/                   |             |\n","|    total_timesteps      | 1568000     |\n","| train/                  |             |\n","|    approx_kl            | 0.013554294 |\n","|    clip_fraction        | 0.0478      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.251       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.171      |\n","|    n_updates            | 2505        |\n","|    policy_gradient_loss | -0.00482    |\n","|    value_loss           | 0.0392      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 192     |\n","|    time_elapsed    | 4333    |\n","|    total_timesteps | 1572864 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 363         |\n","|    iterations           | 193         |\n","|    time_elapsed         | 4350        |\n","|    total_timesteps      | 1581056     |\n","| train/                  |             |\n","|    approx_kl            | 0.017346613 |\n","|    clip_fraction        | 0.0497      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.234       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.164      |\n","|    n_updates            | 2510        |\n","|    policy_gradient_loss | -0.00965    |\n","|    value_loss           | 0.0419      |\n","-----------------------------------------\n","Eval num_timesteps=1584000, episode_reward=1.00 +/- 1.26\n","Episode length: 180.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 180         |\n","|    mean_reward          | 1           |\n","| time/                   |             |\n","|    total_timesteps      | 1584000     |\n","| train/                  |             |\n","|    approx_kl            | 0.016400779 |\n","|    clip_fraction        | 0.0501      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.208       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.155      |\n","|    n_updates            | 2515        |\n","|    policy_gradient_loss | -0.00625    |\n","|    value_loss           | 0.0361      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 363     |\n","|    iterations      | 194     |\n","|    time_elapsed    | 4376    |\n","|    total_timesteps | 1589248 |\n","--------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 363        |\n","|    iterations           | 195        |\n","|    time_elapsed         | 4393       |\n","|    total_timesteps      | 1597440    |\n","| train/                  |            |\n","|    approx_kl            | 0.01280838 |\n","|    clip_fraction        | 0.0433     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.75      |\n","|    explained_variance   | 0.0557     |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.173     |\n","|    n_updates            | 2520       |\n","|    policy_gradient_loss | -0.00742   |\n","|    value_loss           | 0.0407     |\n","----------------------------------------\n","Eval num_timesteps=1600000, episode_reward=0.40 +/- 0.49\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0.4         |\n","| time/                   |             |\n","|    total_timesteps      | 1600000     |\n","| train/                  |             |\n","|    approx_kl            | 0.012500874 |\n","|    clip_fraction        | 0.0431      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.153       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.174      |\n","|    n_updates            | 2525        |\n","|    policy_gradient_loss | -0.00685    |\n","|    value_loss           | 0.0435      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 363     |\n","|    iterations      | 196     |\n","|    time_elapsed    | 4419    |\n","|    total_timesteps | 1605632 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 363         |\n","|    iterations           | 197         |\n","|    time_elapsed         | 4437        |\n","|    total_timesteps      | 1613824     |\n","| train/                  |             |\n","|    approx_kl            | 0.014274074 |\n","|    clip_fraction        | 0.0552      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.76       |\n","|    explained_variance   | 0.196       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.166      |\n","|    n_updates            | 2530        |\n","|    policy_gradient_loss | -0.00794    |\n","|    value_loss           | 0.0467      |\n","-----------------------------------------\n","Eval num_timesteps=1616000, episode_reward=0.80 +/- 1.17\n","Episode length: 220.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 220         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 1616000     |\n","| train/                  |             |\n","|    approx_kl            | 0.013336999 |\n","|    clip_fraction        | 0.0427      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.0359      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.183      |\n","|    n_updates            | 2535        |\n","|    policy_gradient_loss | -0.00724    |\n","|    value_loss           | 0.048       |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 363     |\n","|    iterations      | 198     |\n","|    time_elapsed    | 4465    |\n","|    total_timesteps | 1622016 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 363         |\n","|    iterations           | 199         |\n","|    time_elapsed         | 4482        |\n","|    total_timesteps      | 1630208     |\n","| train/                  |             |\n","|    approx_kl            | 0.014443679 |\n","|    clip_fraction        | 0.0445      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | -0.0759     |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.177      |\n","|    n_updates            | 2540        |\n","|    policy_gradient_loss | -0.00727    |\n","|    value_loss           | 0.0466      |\n","-----------------------------------------\n","Eval num_timesteps=1632000, episode_reward=0.60 +/- 0.80\n","Episode length: 196.00 +/- 16.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 196         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 1632000     |\n","| train/                  |             |\n","|    approx_kl            | 0.017491842 |\n","|    clip_fraction        | 0.0587      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.0599      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.179      |\n","|    n_updates            | 2545        |\n","|    policy_gradient_loss | -0.00793    |\n","|    value_loss           | 0.0445      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 363     |\n","|    iterations      | 200     |\n","|    time_elapsed    | 4510    |\n","|    total_timesteps | 1638400 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 363         |\n","|    iterations           | 201         |\n","|    time_elapsed         | 4526        |\n","|    total_timesteps      | 1646592     |\n","| train/                  |             |\n","|    approx_kl            | 0.014958794 |\n","|    clip_fraction        | 0.0462      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.0139      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.178      |\n","|    n_updates            | 2550        |\n","|    policy_gradient_loss | -0.00854    |\n","|    value_loss           | 0.0401      |\n","-----------------------------------------\n","Eval num_timesteps=1648000, episode_reward=0.80 +/- 1.17\n","Episode length: 168.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 168         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 1648000     |\n","| train/                  |             |\n","|    approx_kl            | 0.016269388 |\n","|    clip_fraction        | 0.0504      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.139       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.194      |\n","|    n_updates            | 2555        |\n","|    policy_gradient_loss | -0.00725    |\n","|    value_loss           | 0.0331      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 363     |\n","|    iterations      | 202     |\n","|    time_elapsed    | 4554    |\n","|    total_timesteps | 1654784 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 363         |\n","|    iterations           | 203         |\n","|    time_elapsed         | 4570        |\n","|    total_timesteps      | 1662976     |\n","| train/                  |             |\n","|    approx_kl            | 0.014817945 |\n","|    clip_fraction        | 0.0462      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.164       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.179      |\n","|    n_updates            | 2560        |\n","|    policy_gradient_loss | -0.00836    |\n","|    value_loss           | 0.0386      |\n","-----------------------------------------\n","Eval num_timesteps=1664000, episode_reward=1.00 +/- 1.26\n","Episode length: 216.00 +/- 24.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 216        |\n","|    mean_reward          | 1          |\n","| time/                   |            |\n","|    total_timesteps      | 1664000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01082357 |\n","|    clip_fraction        | 0.0304     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.74      |\n","|    explained_variance   | 0.154      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.171     |\n","|    n_updates            | 2565       |\n","|    policy_gradient_loss | -0.0102    |\n","|    value_loss           | 0.0426     |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 363     |\n","|    iterations      | 204     |\n","|    time_elapsed    | 4603    |\n","|    total_timesteps | 1671168 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 363         |\n","|    iterations           | 205         |\n","|    time_elapsed         | 4619        |\n","|    total_timesteps      | 1679360     |\n","| train/                  |             |\n","|    approx_kl            | 0.013024325 |\n","|    clip_fraction        | 0.0388      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.273       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.198      |\n","|    n_updates            | 2570        |\n","|    policy_gradient_loss | -0.00615    |\n","|    value_loss           | 0.0357      |\n","-----------------------------------------\n","Eval num_timesteps=1680000, episode_reward=0.20 +/- 0.40\n","Episode length: 168.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 168         |\n","|    mean_reward          | 0.2         |\n","| time/                   |             |\n","|    total_timesteps      | 1680000     |\n","| train/                  |             |\n","|    approx_kl            | 0.016558163 |\n","|    clip_fraction        | 0.0619      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.0971      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.165      |\n","|    n_updates            | 2575        |\n","|    policy_gradient_loss | -0.00991    |\n","|    value_loss           | 0.0435      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 363     |\n","|    iterations      | 206     |\n","|    time_elapsed    | 4646    |\n","|    total_timesteps | 1687552 |\n","--------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 363       |\n","|    iterations           | 207       |\n","|    time_elapsed         | 4662      |\n","|    total_timesteps      | 1695744   |\n","| train/                  |           |\n","|    approx_kl            | 0.0106447 |\n","|    clip_fraction        | 0.0333    |\n","|    clip_range           | 0.3       |\n","|    entropy_loss         | -1.75     |\n","|    explained_variance   | 0.241     |\n","|    learning_rate        | 0.000622  |\n","|    loss                 | -0.182    |\n","|    n_updates            | 2580      |\n","|    policy_gradient_loss | -0.00723  |\n","|    value_loss           | 0.0451    |\n","---------------------------------------\n","Eval num_timesteps=1696000, episode_reward=1.40 +/- 1.74\n","Episode length: 240.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 240         |\n","|    mean_reward          | 1.4         |\n","| time/                   |             |\n","|    total_timesteps      | 1696000     |\n","| train/                  |             |\n","|    approx_kl            | 0.012662988 |\n","|    clip_fraction        | 0.0401      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.245       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.171      |\n","|    n_updates            | 2585        |\n","|    policy_gradient_loss | -0.00799    |\n","|    value_loss           | 0.0471      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 363     |\n","|    iterations      | 208     |\n","|    time_elapsed    | 4693    |\n","|    total_timesteps | 1703936 |\n","--------------------------------\n","Eval num_timesteps=1712000, episode_reward=0.20 +/- 0.40\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0.2         |\n","| time/                   |             |\n","|    total_timesteps      | 1712000     |\n","| train/                  |             |\n","|    approx_kl            | 0.012581697 |\n","|    clip_fraction        | 0.0426      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.23        |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.158      |\n","|    n_updates            | 2590        |\n","|    policy_gradient_loss | -0.00865    |\n","|    value_loss           | 0.0505      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 209     |\n","|    time_elapsed    | 4718    |\n","|    total_timesteps | 1712128 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 363         |\n","|    iterations           | 210         |\n","|    time_elapsed         | 4736        |\n","|    total_timesteps      | 1720320     |\n","| train/                  |             |\n","|    approx_kl            | 0.012819005 |\n","|    clip_fraction        | 0.035       |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.133       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.177      |\n","|    n_updates            | 2595        |\n","|    policy_gradient_loss | -0.0087     |\n","|    value_loss           | 0.0492      |\n","-----------------------------------------\n","Eval num_timesteps=1728000, episode_reward=0.20 +/- 0.40\n","Episode length: 196.00 +/- 64.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 196         |\n","|    mean_reward          | 0.2         |\n","| time/                   |             |\n","|    total_timesteps      | 1728000     |\n","| train/                  |             |\n","|    approx_kl            | 0.015822321 |\n","|    clip_fraction        | 0.0507      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.299       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.126      |\n","|    n_updates            | 2600        |\n","|    policy_gradient_loss | -0.00431    |\n","|    value_loss           | 0.0415      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 211     |\n","|    time_elapsed    | 4769    |\n","|    total_timesteps | 1728512 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 212         |\n","|    time_elapsed         | 4785        |\n","|    total_timesteps      | 1736704     |\n","| train/                  |             |\n","|    approx_kl            | 0.013705159 |\n","|    clip_fraction        | 0.0388      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.189       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.161      |\n","|    n_updates            | 2605        |\n","|    policy_gradient_loss | -0.00638    |\n","|    value_loss           | 0.0448      |\n","-----------------------------------------\n","Eval num_timesteps=1744000, episode_reward=1.00 +/- 1.55\n","Episode length: 180.00 +/- 32.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 180         |\n","|    mean_reward          | 1           |\n","| time/                   |             |\n","|    total_timesteps      | 1744000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014253874 |\n","|    clip_fraction        | 0.034       |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.16        |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.162      |\n","|    n_updates            | 2610        |\n","|    policy_gradient_loss | -0.0065     |\n","|    value_loss           | 0.0385      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 213     |\n","|    time_elapsed    | 4816    |\n","|    total_timesteps | 1744896 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 214         |\n","|    time_elapsed         | 4831        |\n","|    total_timesteps      | 1753088     |\n","| train/                  |             |\n","|    approx_kl            | 0.013482224 |\n","|    clip_fraction        | 0.0469      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.156       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.159      |\n","|    n_updates            | 2615        |\n","|    policy_gradient_loss | -0.00747    |\n","|    value_loss           | 0.0386      |\n","-----------------------------------------\n","Eval num_timesteps=1760000, episode_reward=0.60 +/- 0.80\n","Episode length: 196.00 +/- 16.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 196         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 1760000     |\n","| train/                  |             |\n","|    approx_kl            | 0.009753406 |\n","|    clip_fraction        | 0.034       |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.227       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.17       |\n","|    n_updates            | 2620        |\n","|    policy_gradient_loss | -0.00756    |\n","|    value_loss           | 0.043       |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 215     |\n","|    time_elapsed    | 4860    |\n","|    total_timesteps | 1761280 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 216         |\n","|    time_elapsed         | 4876        |\n","|    total_timesteps      | 1769472     |\n","| train/                  |             |\n","|    approx_kl            | 0.014538908 |\n","|    clip_fraction        | 0.0588      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.13        |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.173      |\n","|    n_updates            | 2625        |\n","|    policy_gradient_loss | -0.00783    |\n","|    value_loss           | 0.0466      |\n","-----------------------------------------\n","Eval num_timesteps=1776000, episode_reward=1.40 +/- 2.33\n","Episode length: 244.00 +/- 40.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 244         |\n","|    mean_reward          | 1.4         |\n","| time/                   |             |\n","|    total_timesteps      | 1776000     |\n","| train/                  |             |\n","|    approx_kl            | 0.015031911 |\n","|    clip_fraction        | 0.056       |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.259       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.159      |\n","|    n_updates            | 2630        |\n","|    policy_gradient_loss | -0.00892    |\n","|    value_loss           | 0.0351      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 217     |\n","|    time_elapsed    | 4908    |\n","|    total_timesteps | 1777664 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 218         |\n","|    time_elapsed         | 4925        |\n","|    total_timesteps      | 1785856     |\n","| train/                  |             |\n","|    approx_kl            | 0.016810866 |\n","|    clip_fraction        | 0.0585      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.142       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.164      |\n","|    n_updates            | 2635        |\n","|    policy_gradient_loss | -0.00839    |\n","|    value_loss           | 0.0526      |\n","-----------------------------------------\n","Eval num_timesteps=1792000, episode_reward=0.60 +/- 0.80\n","Episode length: 164.00 +/- 0.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 164        |\n","|    mean_reward          | 0.6        |\n","| time/                   |            |\n","|    total_timesteps      | 1792000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01164044 |\n","|    clip_fraction        | 0.0448     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.74      |\n","|    explained_variance   | 0.252      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.146     |\n","|    n_updates            | 2640       |\n","|    policy_gradient_loss | -0.0067    |\n","|    value_loss           | 0.0562     |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 219     |\n","|    time_elapsed    | 4951    |\n","|    total_timesteps | 1794048 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 220         |\n","|    time_elapsed         | 4968        |\n","|    total_timesteps      | 1802240     |\n","| train/                  |             |\n","|    approx_kl            | 0.014326959 |\n","|    clip_fraction        | 0.0506      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.24        |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.148      |\n","|    n_updates            | 2645        |\n","|    policy_gradient_loss | -0.00838    |\n","|    value_loss           | 0.0435      |\n","-----------------------------------------\n","Eval num_timesteps=1808000, episode_reward=2.00 +/- 3.10\n","Episode length: 324.00 +/- 80.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 324          |\n","|    mean_reward          | 2            |\n","| time/                   |              |\n","|    total_timesteps      | 1808000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0111670215 |\n","|    clip_fraction        | 0.0364       |\n","|    clip_range           | 0.3          |\n","|    entropy_loss         | -1.73        |\n","|    explained_variance   | 0.328        |\n","|    learning_rate        | 0.000622     |\n","|    loss                 | -0.161       |\n","|    n_updates            | 2650         |\n","|    policy_gradient_loss | -0.00886     |\n","|    value_loss           | 0.0422       |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 221     |\n","|    time_elapsed    | 5003    |\n","|    total_timesteps | 1810432 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 222         |\n","|    time_elapsed         | 5021        |\n","|    total_timesteps      | 1818624     |\n","| train/                  |             |\n","|    approx_kl            | 0.017751524 |\n","|    clip_fraction        | 0.0532      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.245       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.175      |\n","|    n_updates            | 2655        |\n","|    policy_gradient_loss | -0.00847    |\n","|    value_loss           | 0.0511      |\n","-----------------------------------------\n","Eval num_timesteps=1824000, episode_reward=0.60 +/- 1.20\n","Episode length: 168.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 168         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 1824000     |\n","| train/                  |             |\n","|    approx_kl            | 0.011031115 |\n","|    clip_fraction        | 0.0457      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.229       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.186      |\n","|    n_updates            | 2660        |\n","|    policy_gradient_loss | -0.00642    |\n","|    value_loss           | 0.0436      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 223     |\n","|    time_elapsed    | 5048    |\n","|    total_timesteps | 1826816 |\n","--------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 362        |\n","|    iterations           | 224        |\n","|    time_elapsed         | 5065       |\n","|    total_timesteps      | 1835008    |\n","| train/                  |            |\n","|    approx_kl            | 0.01258965 |\n","|    clip_fraction        | 0.0526     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.73      |\n","|    explained_variance   | 0.238      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.159     |\n","|    n_updates            | 2665       |\n","|    policy_gradient_loss | -0.00822   |\n","|    value_loss           | 0.0441     |\n","----------------------------------------\n","Eval num_timesteps=1840000, episode_reward=0.80 +/- 1.17\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 1840000     |\n","| train/                  |             |\n","|    approx_kl            | 0.013119798 |\n","|    clip_fraction        | 0.0386      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.249       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.162      |\n","|    n_updates            | 2670        |\n","|    policy_gradient_loss | -0.00967    |\n","|    value_loss           | 0.0521      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 225     |\n","|    time_elapsed    | 5091    |\n","|    total_timesteps | 1843200 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 362          |\n","|    iterations           | 226          |\n","|    time_elapsed         | 5109         |\n","|    total_timesteps      | 1851392      |\n","| train/                  |              |\n","|    approx_kl            | 0.0142093375 |\n","|    clip_fraction        | 0.0466       |\n","|    clip_range           | 0.3          |\n","|    entropy_loss         | -1.74        |\n","|    explained_variance   | 0.182        |\n","|    learning_rate        | 0.000622     |\n","|    loss                 | -0.157       |\n","|    n_updates            | 2675         |\n","|    policy_gradient_loss | -0.00552     |\n","|    value_loss           | 0.0452       |\n","------------------------------------------\n","Eval num_timesteps=1856000, episode_reward=0.40 +/- 0.49\n","Episode length: 168.00 +/- 8.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 168        |\n","|    mean_reward          | 0.4        |\n","| time/                   |            |\n","|    total_timesteps      | 1856000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01695079 |\n","|    clip_fraction        | 0.066      |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.74      |\n","|    explained_variance   | 0.233      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.167     |\n","|    n_updates            | 2680       |\n","|    policy_gradient_loss | -0.00752   |\n","|    value_loss           | 0.0482     |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 227     |\n","|    time_elapsed    | 5135    |\n","|    total_timesteps | 1859584 |\n","--------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 362        |\n","|    iterations           | 228        |\n","|    time_elapsed         | 5152       |\n","|    total_timesteps      | 1867776    |\n","| train/                  |            |\n","|    approx_kl            | 0.01808894 |\n","|    clip_fraction        | 0.0612     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.74      |\n","|    explained_variance   | 0.167      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.162     |\n","|    n_updates            | 2685       |\n","|    policy_gradient_loss | -0.00662   |\n","|    value_loss           | 0.0422     |\n","----------------------------------------\n","Eval num_timesteps=1872000, episode_reward=0.40 +/- 0.49\n","Episode length: 180.00 +/- 32.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 180         |\n","|    mean_reward          | 0.4         |\n","| time/                   |             |\n","|    total_timesteps      | 1872000     |\n","| train/                  |             |\n","|    approx_kl            | 0.018331403 |\n","|    clip_fraction        | 0.0654      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.297       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.169      |\n","|    n_updates            | 2690        |\n","|    policy_gradient_loss | -0.00926    |\n","|    value_loss           | 0.0451      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 229     |\n","|    time_elapsed    | 5181    |\n","|    total_timesteps | 1875968 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 230         |\n","|    time_elapsed         | 5197        |\n","|    total_timesteps      | 1884160     |\n","| train/                  |             |\n","|    approx_kl            | 0.013613377 |\n","|    clip_fraction        | 0.0367      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.25        |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.162      |\n","|    n_updates            | 2695        |\n","|    policy_gradient_loss | -0.00753    |\n","|    value_loss           | 0.0466      |\n","-----------------------------------------\n","Eval num_timesteps=1888000, episode_reward=1.40 +/- 1.85\n","Episode length: 244.00 +/- 40.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 244        |\n","|    mean_reward          | 1.4        |\n","| time/                   |            |\n","|    total_timesteps      | 1888000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01443888 |\n","|    clip_fraction        | 0.041      |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.73      |\n","|    explained_variance   | 0.147      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.159     |\n","|    n_updates            | 2700       |\n","|    policy_gradient_loss | -0.00997   |\n","|    value_loss           | 0.0397     |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 231     |\n","|    time_elapsed    | 5230    |\n","|    total_timesteps | 1892352 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 232         |\n","|    time_elapsed         | 5246        |\n","|    total_timesteps      | 1900544     |\n","| train/                  |             |\n","|    approx_kl            | 0.012716541 |\n","|    clip_fraction        | 0.0498      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.221       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.169      |\n","|    n_updates            | 2705        |\n","|    policy_gradient_loss | -0.00769    |\n","|    value_loss           | 0.0392      |\n","-----------------------------------------\n","Eval num_timesteps=1904000, episode_reward=0.20 +/- 0.40\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0.2         |\n","| time/                   |             |\n","|    total_timesteps      | 1904000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014522855 |\n","|    clip_fraction        | 0.0569      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.147       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.167      |\n","|    n_updates            | 2710        |\n","|    policy_gradient_loss | -0.00714    |\n","|    value_loss           | 0.0362      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 233     |\n","|    time_elapsed    | 5273    |\n","|    total_timesteps | 1908736 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 362          |\n","|    iterations           | 234          |\n","|    time_elapsed         | 5289         |\n","|    total_timesteps      | 1916928      |\n","| train/                  |              |\n","|    approx_kl            | 0.0147088645 |\n","|    clip_fraction        | 0.071        |\n","|    clip_range           | 0.3          |\n","|    entropy_loss         | -1.73        |\n","|    explained_variance   | 0.18         |\n","|    learning_rate        | 0.000622     |\n","|    loss                 | -0.18        |\n","|    n_updates            | 2715         |\n","|    policy_gradient_loss | -0.0112      |\n","|    value_loss           | 0.0472       |\n","------------------------------------------\n","Eval num_timesteps=1920000, episode_reward=0.00 +/- 0.00\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0           |\n","| time/                   |             |\n","|    total_timesteps      | 1920000     |\n","| train/                  |             |\n","|    approx_kl            | 0.017715197 |\n","|    clip_fraction        | 0.0649      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.191       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.167      |\n","|    n_updates            | 2720        |\n","|    policy_gradient_loss | -0.00914    |\n","|    value_loss           | 0.0491      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 235     |\n","|    time_elapsed    | 5316    |\n","|    total_timesteps | 1925120 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 236         |\n","|    time_elapsed         | 5331        |\n","|    total_timesteps      | 1933312     |\n","| train/                  |             |\n","|    approx_kl            | 0.012711525 |\n","|    clip_fraction        | 0.0395      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.273       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.185      |\n","|    n_updates            | 2725        |\n","|    policy_gradient_loss | -0.00559    |\n","|    value_loss           | 0.0493      |\n","-----------------------------------------\n","Eval num_timesteps=1936000, episode_reward=0.60 +/- 0.80\n","Episode length: 184.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 184         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 1936000     |\n","| train/                  |             |\n","|    approx_kl            | 0.012759846 |\n","|    clip_fraction        | 0.0352      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.312       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.163      |\n","|    n_updates            | 2730        |\n","|    policy_gradient_loss | -0.00542    |\n","|    value_loss           | 0.0465      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 237     |\n","|    time_elapsed    | 5359    |\n","|    total_timesteps | 1941504 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 238         |\n","|    time_elapsed         | 5375        |\n","|    total_timesteps      | 1949696     |\n","| train/                  |             |\n","|    approx_kl            | 0.013439038 |\n","|    clip_fraction        | 0.0452      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.119       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.167      |\n","|    n_updates            | 2735        |\n","|    policy_gradient_loss | -0.00928    |\n","|    value_loss           | 0.0421      |\n","-----------------------------------------\n","Eval num_timesteps=1952000, episode_reward=1.20 +/- 1.60\n","Episode length: 196.00 +/- 16.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 196         |\n","|    mean_reward          | 1.2         |\n","| time/                   |             |\n","|    total_timesteps      | 1952000     |\n","| train/                  |             |\n","|    approx_kl            | 0.016124189 |\n","|    clip_fraction        | 0.057       |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.259       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.149      |\n","|    n_updates            | 2740        |\n","|    policy_gradient_loss | -0.00747    |\n","|    value_loss           | 0.0316      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 239     |\n","|    time_elapsed    | 5404    |\n","|    total_timesteps | 1957888 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 240         |\n","|    time_elapsed         | 5420        |\n","|    total_timesteps      | 1966080     |\n","| train/                  |             |\n","|    approx_kl            | 0.013812626 |\n","|    clip_fraction        | 0.0601      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.114       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.17       |\n","|    n_updates            | 2745        |\n","|    policy_gradient_loss | -0.0042     |\n","|    value_loss           | 0.0401      |\n","-----------------------------------------\n","Eval num_timesteps=1968000, episode_reward=0.60 +/- 0.80\n","Episode length: 184.00 +/- 0.00\n","---------------------------------------\n","| eval/                   |           |\n","|    mean_ep_length       | 184       |\n","|    mean_reward          | 0.6       |\n","| time/                   |           |\n","|    total_timesteps      | 1968000   |\n","| train/                  |           |\n","|    approx_kl            | 0.0119616 |\n","|    clip_fraction        | 0.0465    |\n","|    clip_range           | 0.3       |\n","|    entropy_loss         | -1.74     |\n","|    explained_variance   | 0.169     |\n","|    learning_rate        | 0.000622  |\n","|    loss                 | -0.172    |\n","|    n_updates            | 2750      |\n","|    policy_gradient_loss | -0.00755  |\n","|    value_loss           | 0.0459    |\n","---------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 241     |\n","|    time_elapsed    | 5447    |\n","|    total_timesteps | 1974272 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 242         |\n","|    time_elapsed         | 5464        |\n","|    total_timesteps      | 1982464     |\n","| train/                  |             |\n","|    approx_kl            | 0.013781507 |\n","|    clip_fraction        | 0.0494      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.226       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.173      |\n","|    n_updates            | 2755        |\n","|    policy_gradient_loss | -0.00767    |\n","|    value_loss           | 0.0371      |\n","-----------------------------------------\n","Eval num_timesteps=1984000, episode_reward=1.20 +/- 1.94\n","Episode length: 220.00 +/- 32.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 220         |\n","|    mean_reward          | 1.2         |\n","| time/                   |             |\n","|    total_timesteps      | 1984000     |\n","| train/                  |             |\n","|    approx_kl            | 0.013667092 |\n","|    clip_fraction        | 0.0447      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.216       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.141      |\n","|    n_updates            | 2760        |\n","|    policy_gradient_loss | -0.00825    |\n","|    value_loss           | 0.0419      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 243     |\n","|    time_elapsed    | 5495    |\n","|    total_timesteps | 1990656 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 244         |\n","|    time_elapsed         | 5513        |\n","|    total_timesteps      | 1998848     |\n","| train/                  |             |\n","|    approx_kl            | 0.014533371 |\n","|    clip_fraction        | 0.0563      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.215       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.178      |\n","|    n_updates            | 2765        |\n","|    policy_gradient_loss | -0.00871    |\n","|    value_loss           | 0.0459      |\n","-----------------------------------------\n","Eval num_timesteps=2000000, episode_reward=1.60 +/- 0.80\n","Episode length: 252.00 +/- 24.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 252         |\n","|    mean_reward          | 1.6         |\n","| time/                   |             |\n","|    total_timesteps      | 2000000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014660696 |\n","|    clip_fraction        | 0.0568      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.228       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.181      |\n","|    n_updates            | 2770        |\n","|    policy_gradient_loss | -0.0103     |\n","|    value_loss           | 0.052       |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 245     |\n","|    time_elapsed    | 5542    |\n","|    total_timesteps | 2007040 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 246         |\n","|    time_elapsed         | 5560        |\n","|    total_timesteps      | 2015232     |\n","| train/                  |             |\n","|    approx_kl            | 0.017754514 |\n","|    clip_fraction        | 0.0637      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | -0.104      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.174      |\n","|    n_updates            | 2775        |\n","|    policy_gradient_loss | -0.00708    |\n","|    value_loss           | 0.0352      |\n","-----------------------------------------\n","Eval num_timesteps=2016000, episode_reward=0.80 +/- 0.98\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 2016000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014333744 |\n","|    clip_fraction        | 0.0542      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.274       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.159      |\n","|    n_updates            | 2780        |\n","|    policy_gradient_loss | -0.00868    |\n","|    value_loss           | 0.0483      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 247     |\n","|    time_elapsed    | 5586    |\n","|    total_timesteps | 2023424 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 248         |\n","|    time_elapsed         | 5603        |\n","|    total_timesteps      | 2031616     |\n","| train/                  |             |\n","|    approx_kl            | 0.015754156 |\n","|    clip_fraction        | 0.0559      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.217       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.166      |\n","|    n_updates            | 2785        |\n","|    policy_gradient_loss | -0.0102     |\n","|    value_loss           | 0.0506      |\n","-----------------------------------------\n","Eval num_timesteps=2032000, episode_reward=0.60 +/- 0.49\n","Episode length: 176.00 +/- 24.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 176         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 2032000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014239939 |\n","|    clip_fraction        | 0.049       |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.71       |\n","|    explained_variance   | 0.196       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.136      |\n","|    n_updates            | 2790        |\n","|    policy_gradient_loss | -0.00785    |\n","|    value_loss           | 0.0443      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 362     |\n","|    iterations      | 249     |\n","|    time_elapsed    | 5632    |\n","|    total_timesteps | 2039808 |\n","--------------------------------\n","Eval num_timesteps=2048000, episode_reward=0.60 +/- 0.80\n","Episode length: 168.00 +/- 8.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 168        |\n","|    mean_reward          | 0.6        |\n","| time/                   |            |\n","|    total_timesteps      | 2048000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01659854 |\n","|    clip_fraction        | 0.0565     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.74      |\n","|    explained_variance   | 0.214      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.166     |\n","|    n_updates            | 2795       |\n","|    policy_gradient_loss | -0.00792   |\n","|    value_loss           | 0.0394     |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 250     |\n","|    time_elapsed    | 5660    |\n","|    total_timesteps | 2048000 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 251         |\n","|    time_elapsed         | 5676        |\n","|    total_timesteps      | 2056192     |\n","| train/                  |             |\n","|    approx_kl            | 0.012864253 |\n","|    clip_fraction        | 0.0453      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.0495      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.162      |\n","|    n_updates            | 2800        |\n","|    policy_gradient_loss | -0.00421    |\n","|    value_loss           | 0.0348      |\n","-----------------------------------------\n","Eval num_timesteps=2064000, episode_reward=1.00 +/- 1.26\n","Episode length: 168.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 168         |\n","|    mean_reward          | 1           |\n","| time/                   |             |\n","|    total_timesteps      | 2064000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014295416 |\n","|    clip_fraction        | 0.0448      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.116       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.174      |\n","|    n_updates            | 2805        |\n","|    policy_gradient_loss | -0.0116     |\n","|    value_loss           | 0.0448      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 252     |\n","|    time_elapsed    | 5704    |\n","|    total_timesteps | 2064384 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 253         |\n","|    time_elapsed         | 5719        |\n","|    total_timesteps      | 2072576     |\n","| train/                  |             |\n","|    approx_kl            | 0.017561093 |\n","|    clip_fraction        | 0.054       |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.246       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.181      |\n","|    n_updates            | 2810        |\n","|    policy_gradient_loss | -0.00746    |\n","|    value_loss           | 0.0442      |\n","-----------------------------------------\n","Eval num_timesteps=2080000, episode_reward=0.40 +/- 0.80\n","Episode length: 204.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 204         |\n","|    mean_reward          | 0.4         |\n","| time/                   |             |\n","|    total_timesteps      | 2080000     |\n","| train/                  |             |\n","|    approx_kl            | 0.015517329 |\n","|    clip_fraction        | 0.0468      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.196       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.171      |\n","|    n_updates            | 2815        |\n","|    policy_gradient_loss | -0.00738    |\n","|    value_loss           | 0.0427      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 254     |\n","|    time_elapsed    | 5748    |\n","|    total_timesteps | 2080768 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 255         |\n","|    time_elapsed         | 5764        |\n","|    total_timesteps      | 2088960     |\n","| train/                  |             |\n","|    approx_kl            | 0.014137994 |\n","|    clip_fraction        | 0.0431      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.182       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.18       |\n","|    n_updates            | 2820        |\n","|    policy_gradient_loss | -0.00896    |\n","|    value_loss           | 0.0395      |\n","-----------------------------------------\n","Eval num_timesteps=2096000, episode_reward=1.00 +/- 1.55\n","Episode length: 228.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 228         |\n","|    mean_reward          | 1           |\n","| time/                   |             |\n","|    total_timesteps      | 2096000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014228343 |\n","|    clip_fraction        | 0.0372      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.164       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.168      |\n","|    n_updates            | 2825        |\n","|    policy_gradient_loss | -0.00964    |\n","|    value_loss           | 0.0371      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 256     |\n","|    time_elapsed    | 5794    |\n","|    total_timesteps | 2097152 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 257         |\n","|    time_elapsed         | 5811        |\n","|    total_timesteps      | 2105344     |\n","| train/                  |             |\n","|    approx_kl            | 0.011717487 |\n","|    clip_fraction        | 0.0469      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.189       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.173      |\n","|    n_updates            | 2830        |\n","|    policy_gradient_loss | -0.00747    |\n","|    value_loss           | 0.0389      |\n","-----------------------------------------\n","Eval num_timesteps=2112000, episode_reward=1.20 +/- 1.60\n","Episode length: 240.00 +/- 8.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 240        |\n","|    mean_reward          | 1.2        |\n","| time/                   |            |\n","|    total_timesteps      | 2112000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01900221 |\n","|    clip_fraction        | 0.0683     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.73      |\n","|    explained_variance   | 0.0316     |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.169     |\n","|    n_updates            | 2835       |\n","|    policy_gradient_loss | -0.0123    |\n","|    value_loss           | 0.0506     |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 258     |\n","|    time_elapsed    | 5841    |\n","|    total_timesteps | 2113536 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 259         |\n","|    time_elapsed         | 5859        |\n","|    total_timesteps      | 2121728     |\n","| train/                  |             |\n","|    approx_kl            | 0.013635176 |\n","|    clip_fraction        | 0.0478      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.245       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.16       |\n","|    n_updates            | 2840        |\n","|    policy_gradient_loss | -0.00816    |\n","|    value_loss           | 0.0549      |\n","-----------------------------------------\n","Eval num_timesteps=2128000, episode_reward=0.20 +/- 0.40\n","Episode length: 180.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 180         |\n","|    mean_reward          | 0.2         |\n","| time/                   |             |\n","|    total_timesteps      | 2128000     |\n","| train/                  |             |\n","|    approx_kl            | 0.013567711 |\n","|    clip_fraction        | 0.0452      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.0772      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.18       |\n","|    n_updates            | 2845        |\n","|    policy_gradient_loss | -0.0102     |\n","|    value_loss           | 0.0381      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 260     |\n","|    time_elapsed    | 5885    |\n","|    total_timesteps | 2129920 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 261         |\n","|    time_elapsed         | 5904        |\n","|    total_timesteps      | 2138112     |\n","| train/                  |             |\n","|    approx_kl            | 0.012818728 |\n","|    clip_fraction        | 0.0423      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.222       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.172      |\n","|    n_updates            | 2850        |\n","|    policy_gradient_loss | -0.00793    |\n","|    value_loss           | 0.0388      |\n","-----------------------------------------\n","Eval num_timesteps=2144000, episode_reward=1.00 +/- 1.55\n","Episode length: 180.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 180         |\n","|    mean_reward          | 1           |\n","| time/                   |             |\n","|    total_timesteps      | 2144000     |\n","| train/                  |             |\n","|    approx_kl            | 0.009471369 |\n","|    clip_fraction        | 0.0284      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.14        |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.163      |\n","|    n_updates            | 2855        |\n","|    policy_gradient_loss | -0.0046     |\n","|    value_loss           | 0.045       |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 262     |\n","|    time_elapsed    | 5930    |\n","|    total_timesteps | 2146304 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 263         |\n","|    time_elapsed         | 5948        |\n","|    total_timesteps      | 2154496     |\n","| train/                  |             |\n","|    approx_kl            | 0.012235539 |\n","|    clip_fraction        | 0.0339      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.116       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.139      |\n","|    n_updates            | 2860        |\n","|    policy_gradient_loss | -0.00609    |\n","|    value_loss           | 0.0445      |\n","-----------------------------------------\n","Eval num_timesteps=2160000, episode_reward=0.60 +/- 1.20\n","Episode length: 180.00 +/- 32.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 180         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 2160000     |\n","| train/                  |             |\n","|    approx_kl            | 0.011754777 |\n","|    clip_fraction        | 0.0357      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.234       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.146      |\n","|    n_updates            | 2865        |\n","|    policy_gradient_loss | -0.00418    |\n","|    value_loss           | 0.0375      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 264     |\n","|    time_elapsed    | 5977    |\n","|    total_timesteps | 2162688 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 265         |\n","|    time_elapsed         | 5995        |\n","|    total_timesteps      | 2170880     |\n","| train/                  |             |\n","|    approx_kl            | 0.015853478 |\n","|    clip_fraction        | 0.0565      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.143       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.19       |\n","|    n_updates            | 2870        |\n","|    policy_gradient_loss | -0.00928    |\n","|    value_loss           | 0.0462      |\n","-----------------------------------------\n","Eval num_timesteps=2176000, episode_reward=0.80 +/- 0.98\n","Episode length: 180.00 +/- 32.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 180         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 2176000     |\n","| train/                  |             |\n","|    approx_kl            | 0.013000144 |\n","|    clip_fraction        | 0.0377      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.0681      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.192      |\n","|    n_updates            | 2875        |\n","|    policy_gradient_loss | -0.00896    |\n","|    value_loss           | 0.0436      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 266     |\n","|    time_elapsed    | 6025    |\n","|    total_timesteps | 2179072 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 267         |\n","|    time_elapsed         | 6042        |\n","|    total_timesteps      | 2187264     |\n","| train/                  |             |\n","|    approx_kl            | 0.013664909 |\n","|    clip_fraction        | 0.0436      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.26        |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.147      |\n","|    n_updates            | 2880        |\n","|    policy_gradient_loss | -0.00357    |\n","|    value_loss           | 0.0465      |\n","-----------------------------------------\n","Eval num_timesteps=2192000, episode_reward=1.00 +/- 1.26\n","Episode length: 168.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 168         |\n","|    mean_reward          | 1           |\n","| time/                   |             |\n","|    total_timesteps      | 2192000     |\n","| train/                  |             |\n","|    approx_kl            | 0.011853134 |\n","|    clip_fraction        | 0.03        |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.25        |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.154      |\n","|    n_updates            | 2885        |\n","|    policy_gradient_loss | -0.00849    |\n","|    value_loss           | 0.0478      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 268     |\n","|    time_elapsed    | 6069    |\n","|    total_timesteps | 2195456 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 362         |\n","|    iterations           | 269         |\n","|    time_elapsed         | 6085        |\n","|    total_timesteps      | 2203648     |\n","| train/                  |             |\n","|    approx_kl            | 0.013010085 |\n","|    clip_fraction        | 0.0453      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.199       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.164      |\n","|    n_updates            | 2890        |\n","|    policy_gradient_loss | -0.00573    |\n","|    value_loss           | 0.0428      |\n","-----------------------------------------\n","Eval num_timesteps=2208000, episode_reward=1.00 +/- 1.55\n","Episode length: 220.00 +/- 32.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 220         |\n","|    mean_reward          | 1           |\n","| time/                   |             |\n","|    total_timesteps      | 2208000     |\n","| train/                  |             |\n","|    approx_kl            | 0.010178676 |\n","|    clip_fraction        | 0.0301      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.258       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.171      |\n","|    n_updates            | 2895        |\n","|    policy_gradient_loss | -0.00515    |\n","|    value_loss           | 0.0408      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 270     |\n","|    time_elapsed    | 6118    |\n","|    total_timesteps | 2211840 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 361         |\n","|    iterations           | 271         |\n","|    time_elapsed         | 6134        |\n","|    total_timesteps      | 2220032     |\n","| train/                  |             |\n","|    approx_kl            | 0.014808536 |\n","|    clip_fraction        | 0.0557      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.221       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.159      |\n","|    n_updates            | 2900        |\n","|    policy_gradient_loss | -0.0058     |\n","|    value_loss           | 0.0595      |\n","-----------------------------------------\n","Eval num_timesteps=2224000, episode_reward=2.60 +/- 2.50\n","Episode length: 340.00 +/- 88.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 340        |\n","|    mean_reward          | 2.6        |\n","| time/                   |            |\n","|    total_timesteps      | 2224000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01474037 |\n","|    clip_fraction        | 0.0503     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.75      |\n","|    explained_variance   | 0.173      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.131     |\n","|    n_updates            | 2905       |\n","|    policy_gradient_loss | -0.00632   |\n","|    value_loss           | 0.0434     |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 272     |\n","|    time_elapsed    | 6171    |\n","|    total_timesteps | 2228224 |\n","--------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 361        |\n","|    iterations           | 273        |\n","|    time_elapsed         | 6189       |\n","|    total_timesteps      | 2236416    |\n","| train/                  |            |\n","|    approx_kl            | 0.01287101 |\n","|    clip_fraction        | 0.0398     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.72      |\n","|    explained_variance   | 0.212      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.179     |\n","|    n_updates            | 2910       |\n","|    policy_gradient_loss | -0.00788   |\n","|    value_loss           | 0.0426     |\n","----------------------------------------\n","Eval num_timesteps=2240000, episode_reward=0.60 +/- 0.80\n","Episode length: 180.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 180         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 2240000     |\n","| train/                  |             |\n","|    approx_kl            | 0.010846505 |\n","|    clip_fraction        | 0.0377      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.265       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.154      |\n","|    n_updates            | 2915        |\n","|    policy_gradient_loss | -0.00602    |\n","|    value_loss           | 0.0605      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 274     |\n","|    time_elapsed    | 6215    |\n","|    total_timesteps | 2244608 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 361         |\n","|    iterations           | 275         |\n","|    time_elapsed         | 6234        |\n","|    total_timesteps      | 2252800     |\n","| train/                  |             |\n","|    approx_kl            | 0.015190946 |\n","|    clip_fraction        | 0.0519      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.71       |\n","|    explained_variance   | 0.236       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.189      |\n","|    n_updates            | 2920        |\n","|    policy_gradient_loss | -0.00992    |\n","|    value_loss           | 0.0463      |\n","-----------------------------------------\n","Eval num_timesteps=2256000, episode_reward=0.40 +/- 0.80\n","Episode length: 164.00 +/- 0.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 164        |\n","|    mean_reward          | 0.4        |\n","| time/                   |            |\n","|    total_timesteps      | 2256000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01134345 |\n","|    clip_fraction        | 0.0422     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.72      |\n","|    explained_variance   | 0.294      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.172     |\n","|    n_updates            | 2925       |\n","|    policy_gradient_loss | -0.00598   |\n","|    value_loss           | 0.0516     |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 276     |\n","|    time_elapsed    | 6259    |\n","|    total_timesteps | 2260992 |\n","--------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 361        |\n","|    iterations           | 277        |\n","|    time_elapsed         | 6277       |\n","|    total_timesteps      | 2269184    |\n","| train/                  |            |\n","|    approx_kl            | 0.01135322 |\n","|    clip_fraction        | 0.0401     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.73      |\n","|    explained_variance   | 0.287      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.156     |\n","|    n_updates            | 2930       |\n","|    policy_gradient_loss | -0.00405   |\n","|    value_loss           | 0.0514     |\n","----------------------------------------\n","Eval num_timesteps=2272000, episode_reward=0.40 +/- 0.49\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0.4         |\n","| time/                   |             |\n","|    total_timesteps      | 2272000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014623979 |\n","|    clip_fraction        | 0.0499      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.265       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.171      |\n","|    n_updates            | 2935        |\n","|    policy_gradient_loss | -0.00524    |\n","|    value_loss           | 0.0461      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 278     |\n","|    time_elapsed    | 6303    |\n","|    total_timesteps | 2277376 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 361         |\n","|    iterations           | 279         |\n","|    time_elapsed         | 6321        |\n","|    total_timesteps      | 2285568     |\n","| train/                  |             |\n","|    approx_kl            | 0.009635812 |\n","|    clip_fraction        | 0.0314      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.176       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.167      |\n","|    n_updates            | 2940        |\n","|    policy_gradient_loss | -0.00507    |\n","|    value_loss           | 0.0454      |\n","-----------------------------------------\n","Eval num_timesteps=2288000, episode_reward=0.80 +/- 1.60\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 2288000     |\n","| train/                  |             |\n","|    approx_kl            | 0.011781447 |\n","|    clip_fraction        | 0.0415      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.29        |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.17       |\n","|    n_updates            | 2945        |\n","|    policy_gradient_loss | -0.00626    |\n","|    value_loss           | 0.0423      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 280     |\n","|    time_elapsed    | 6346    |\n","|    total_timesteps | 2293760 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 361         |\n","|    iterations           | 281         |\n","|    time_elapsed         | 6365        |\n","|    total_timesteps      | 2301952     |\n","| train/                  |             |\n","|    approx_kl            | 0.011480955 |\n","|    clip_fraction        | 0.0459      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.188       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.151      |\n","|    n_updates            | 2950        |\n","|    policy_gradient_loss | -0.00507    |\n","|    value_loss           | 0.0449      |\n","-----------------------------------------\n","Eval num_timesteps=2304000, episode_reward=0.60 +/- 0.80\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 2304000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014206365 |\n","|    clip_fraction        | 0.0447      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.265       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.166      |\n","|    n_updates            | 2955        |\n","|    policy_gradient_loss | -0.00576    |\n","|    value_loss           | 0.0427      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 282     |\n","|    time_elapsed    | 6390    |\n","|    total_timesteps | 2310144 |\n","--------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 361        |\n","|    iterations           | 283        |\n","|    time_elapsed         | 6408       |\n","|    total_timesteps      | 2318336    |\n","| train/                  |            |\n","|    approx_kl            | 0.01818861 |\n","|    clip_fraction        | 0.0651     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.73      |\n","|    explained_variance   | 0.185      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.16      |\n","|    n_updates            | 2960       |\n","|    policy_gradient_loss | -0.00646   |\n","|    value_loss           | 0.0512     |\n","----------------------------------------\n","Eval num_timesteps=2320000, episode_reward=0.80 +/- 1.17\n","Episode length: 212.00 +/- 16.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 212         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 2320000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014869638 |\n","|    clip_fraction        | 0.0459      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.122       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.166      |\n","|    n_updates            | 2965        |\n","|    policy_gradient_loss | -0.00494    |\n","|    value_loss           | 0.053       |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 284     |\n","|    time_elapsed    | 6438    |\n","|    total_timesteps | 2326528 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 361         |\n","|    iterations           | 285         |\n","|    time_elapsed         | 6455        |\n","|    total_timesteps      | 2334720     |\n","| train/                  |             |\n","|    approx_kl            | 0.015612794 |\n","|    clip_fraction        | 0.047       |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.2         |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.157      |\n","|    n_updates            | 2970        |\n","|    policy_gradient_loss | -0.00508    |\n","|    value_loss           | 0.0555      |\n","-----------------------------------------\n","Eval num_timesteps=2336000, episode_reward=1.00 +/- 1.26\n","Episode length: 224.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 224         |\n","|    mean_reward          | 1           |\n","| time/                   |             |\n","|    total_timesteps      | 2336000     |\n","| train/                  |             |\n","|    approx_kl            | 0.010855604 |\n","|    clip_fraction        | 0.0405      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.289       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.161      |\n","|    n_updates            | 2975        |\n","|    policy_gradient_loss | -0.00696    |\n","|    value_loss           | 0.0536      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 286     |\n","|    time_elapsed    | 6485    |\n","|    total_timesteps | 2342912 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 361         |\n","|    iterations           | 287         |\n","|    time_elapsed         | 6501        |\n","|    total_timesteps      | 2351104     |\n","| train/                  |             |\n","|    approx_kl            | 0.012708084 |\n","|    clip_fraction        | 0.0343      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.294       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.171      |\n","|    n_updates            | 2980        |\n","|    policy_gradient_loss | -0.00466    |\n","|    value_loss           | 0.0451      |\n","-----------------------------------------\n","Eval num_timesteps=2352000, episode_reward=1.40 +/- 1.50\n","Episode length: 248.00 +/- 32.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 248         |\n","|    mean_reward          | 1.4         |\n","| time/                   |             |\n","|    total_timesteps      | 2352000     |\n","| train/                  |             |\n","|    approx_kl            | 0.015553946 |\n","|    clip_fraction        | 0.0608      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.337       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.173      |\n","|    n_updates            | 2985        |\n","|    policy_gradient_loss | -0.00756    |\n","|    value_loss           | 0.0492      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 288     |\n","|    time_elapsed    | 6533    |\n","|    total_timesteps | 2359296 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 361         |\n","|    iterations           | 289         |\n","|    time_elapsed         | 6550        |\n","|    total_timesteps      | 2367488     |\n","| train/                  |             |\n","|    approx_kl            | 0.015615097 |\n","|    clip_fraction        | 0.0371      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.0951      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.16       |\n","|    n_updates            | 2990        |\n","|    policy_gradient_loss | -0.00574    |\n","|    value_loss           | 0.0408      |\n","-----------------------------------------\n","Eval num_timesteps=2368000, episode_reward=0.80 +/- 0.98\n","Episode length: 184.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 184          |\n","|    mean_reward          | 0.8          |\n","| time/                   |              |\n","|    total_timesteps      | 2368000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0137603115 |\n","|    clip_fraction        | 0.0415       |\n","|    clip_range           | 0.3          |\n","|    entropy_loss         | -1.75        |\n","|    explained_variance   | 0.253        |\n","|    learning_rate        | 0.000622     |\n","|    loss                 | -0.154       |\n","|    n_updates            | 2995         |\n","|    policy_gradient_loss | -0.00597     |\n","|    value_loss           | 0.044        |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 290     |\n","|    time_elapsed    | 6579    |\n","|    total_timesteps | 2375680 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 361         |\n","|    iterations           | 291         |\n","|    time_elapsed         | 6596        |\n","|    total_timesteps      | 2383872     |\n","| train/                  |             |\n","|    approx_kl            | 0.014507674 |\n","|    clip_fraction        | 0.0398      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.76       |\n","|    explained_variance   | 0.117       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.164      |\n","|    n_updates            | 3000        |\n","|    policy_gradient_loss | -0.00653    |\n","|    value_loss           | 0.0424      |\n","-----------------------------------------\n","Eval num_timesteps=2384000, episode_reward=0.60 +/- 0.80\n","Episode length: 168.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 168         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 2384000     |\n","| train/                  |             |\n","|    approx_kl            | 0.016960904 |\n","|    clip_fraction        | 0.0423      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.212       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.168      |\n","|    n_updates            | 3005        |\n","|    policy_gradient_loss | -0.0082     |\n","|    value_loss           | 0.0578      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 361     |\n","|    iterations      | 292     |\n","|    time_elapsed    | 6623    |\n","|    total_timesteps | 2392064 |\n","--------------------------------\n","Eval num_timesteps=2400000, episode_reward=0.60 +/- 0.80\n","Episode length: 200.00 +/- 32.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 200         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 2400000     |\n","| train/                  |             |\n","|    approx_kl            | 0.011334601 |\n","|    clip_fraction        | 0.0424      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.76       |\n","|    explained_variance   | 0.187       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.175      |\n","|    n_updates            | 3010        |\n","|    policy_gradient_loss | -0.00551    |\n","|    value_loss           | 0.0429      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 293     |\n","|    time_elapsed    | 6652    |\n","|    total_timesteps | 2400256 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 361         |\n","|    iterations           | 294         |\n","|    time_elapsed         | 6670        |\n","|    total_timesteps      | 2408448     |\n","| train/                  |             |\n","|    approx_kl            | 0.011652412 |\n","|    clip_fraction        | 0.0448      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.76       |\n","|    explained_variance   | 0.215       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.163      |\n","|    n_updates            | 3015        |\n","|    policy_gradient_loss | -0.00781    |\n","|    value_loss           | 0.0454      |\n","-----------------------------------------\n","Eval num_timesteps=2416000, episode_reward=0.80 +/- 1.17\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 2416000     |\n","| train/                  |             |\n","|    approx_kl            | 0.012278492 |\n","|    clip_fraction        | 0.0401      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.0848      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.166      |\n","|    n_updates            | 3020        |\n","|    policy_gradient_loss | -0.0093     |\n","|    value_loss           | 0.0434      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 295     |\n","|    time_elapsed    | 6696    |\n","|    total_timesteps | 2416640 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 361         |\n","|    iterations           | 296         |\n","|    time_elapsed         | 6714        |\n","|    total_timesteps      | 2424832     |\n","| train/                  |             |\n","|    approx_kl            | 0.011868165 |\n","|    clip_fraction        | 0.0363      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.101       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.173      |\n","|    n_updates            | 3025        |\n","|    policy_gradient_loss | -0.0101     |\n","|    value_loss           | 0.0372      |\n","-----------------------------------------\n","Eval num_timesteps=2432000, episode_reward=0.20 +/- 0.40\n","Episode length: 172.00 +/- 16.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 172         |\n","|    mean_reward          | 0.2         |\n","| time/                   |             |\n","|    total_timesteps      | 2432000     |\n","| train/                  |             |\n","|    approx_kl            | 0.015214246 |\n","|    clip_fraction        | 0.0527      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.264       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.166      |\n","|    n_updates            | 3030        |\n","|    policy_gradient_loss | -0.0105     |\n","|    value_loss           | 0.0487      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 297     |\n","|    time_elapsed    | 6742    |\n","|    total_timesteps | 2433024 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 361         |\n","|    iterations           | 298         |\n","|    time_elapsed         | 6759        |\n","|    total_timesteps      | 2441216     |\n","| train/                  |             |\n","|    approx_kl            | 0.013752233 |\n","|    clip_fraction        | 0.0446      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.183       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.148      |\n","|    n_updates            | 3035        |\n","|    policy_gradient_loss | -0.00814    |\n","|    value_loss           | 0.04        |\n","-----------------------------------------\n","Eval num_timesteps=2448000, episode_reward=0.80 +/- 1.17\n","Episode length: 196.00 +/- 16.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 196         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 2448000     |\n","| train/                  |             |\n","|    approx_kl            | 0.012385683 |\n","|    clip_fraction        | 0.036       |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.272       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.144      |\n","|    n_updates            | 3040        |\n","|    policy_gradient_loss | -0.00771    |\n","|    value_loss           | 0.0556      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 299     |\n","|    time_elapsed    | 6788    |\n","|    total_timesteps | 2449408 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 361         |\n","|    iterations           | 300         |\n","|    time_elapsed         | 6804        |\n","|    total_timesteps      | 2457600     |\n","| train/                  |             |\n","|    approx_kl            | 0.018224109 |\n","|    clip_fraction        | 0.0523      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.76       |\n","|    explained_variance   | 0.273       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.166      |\n","|    n_updates            | 3045        |\n","|    policy_gradient_loss | -0.00651    |\n","|    value_loss           | 0.0418      |\n","-----------------------------------------\n","Eval num_timesteps=2464000, episode_reward=0.60 +/- 0.80\n","Episode length: 188.00 +/- 48.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 188         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 2464000     |\n","| train/                  |             |\n","|    approx_kl            | 0.013963678 |\n","|    clip_fraction        | 0.0392      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.286       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.168      |\n","|    n_updates            | 3050        |\n","|    policy_gradient_loss | -0.00805    |\n","|    value_loss           | 0.0435      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 301     |\n","|    time_elapsed    | 6838    |\n","|    total_timesteps | 2465792 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 360         |\n","|    iterations           | 302         |\n","|    time_elapsed         | 6854        |\n","|    total_timesteps      | 2473984     |\n","| train/                  |             |\n","|    approx_kl            | 0.014379524 |\n","|    clip_fraction        | 0.0399      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.284       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.18       |\n","|    n_updates            | 3055        |\n","|    policy_gradient_loss | -0.00577    |\n","|    value_loss           | 0.0447      |\n","-----------------------------------------\n","Eval num_timesteps=2480000, episode_reward=0.40 +/- 0.80\n","Episode length: 184.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 184         |\n","|    mean_reward          | 0.4         |\n","| time/                   |             |\n","|    total_timesteps      | 2480000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014005087 |\n","|    clip_fraction        | 0.0461      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.76       |\n","|    explained_variance   | 0.0538      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.162      |\n","|    n_updates            | 3060        |\n","|    policy_gradient_loss | -0.00682    |\n","|    value_loss           | 0.0444      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 303     |\n","|    time_elapsed    | 6882    |\n","|    total_timesteps | 2482176 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 361         |\n","|    iterations           | 304         |\n","|    time_elapsed         | 6898        |\n","|    total_timesteps      | 2490368     |\n","| train/                  |             |\n","|    approx_kl            | 0.013506106 |\n","|    clip_fraction        | 0.036       |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.76       |\n","|    explained_variance   | 0.169       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.165      |\n","|    n_updates            | 3065        |\n","|    policy_gradient_loss | -0.00685    |\n","|    value_loss           | 0.0349      |\n","-----------------------------------------\n","Eval num_timesteps=2496000, episode_reward=1.40 +/- 1.96\n","Episode length: 236.00 +/- 64.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 236         |\n","|    mean_reward          | 1.4         |\n","| time/                   |             |\n","|    total_timesteps      | 2496000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014273025 |\n","|    clip_fraction        | 0.0505      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.191       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.172      |\n","|    n_updates            | 3070        |\n","|    policy_gradient_loss | -0.00518    |\n","|    value_loss           | 0.0541      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 305     |\n","|    time_elapsed    | 6933    |\n","|    total_timesteps | 2498560 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 360         |\n","|    iterations           | 306         |\n","|    time_elapsed         | 6951        |\n","|    total_timesteps      | 2506752     |\n","| train/                  |             |\n","|    approx_kl            | 0.015859088 |\n","|    clip_fraction        | 0.0437      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.0804      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.174      |\n","|    n_updates            | 3075        |\n","|    policy_gradient_loss | -0.00849    |\n","|    value_loss           | 0.0426      |\n","-----------------------------------------\n","Eval num_timesteps=2512000, episode_reward=1.20 +/- 0.98\n","Episode length: 228.00 +/- 32.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 228         |\n","|    mean_reward          | 1.2         |\n","| time/                   |             |\n","|    total_timesteps      | 2512000     |\n","| train/                  |             |\n","|    approx_kl            | 0.011733634 |\n","|    clip_fraction        | 0.0385      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.2         |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.171      |\n","|    n_updates            | 3080        |\n","|    policy_gradient_loss | -0.007      |\n","|    value_loss           | 0.059       |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 307     |\n","|    time_elapsed    | 6980    |\n","|    total_timesteps | 2514944 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 360         |\n","|    iterations           | 308         |\n","|    time_elapsed         | 6997        |\n","|    total_timesteps      | 2523136     |\n","| train/                  |             |\n","|    approx_kl            | 0.014014007 |\n","|    clip_fraction        | 0.0444      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.107       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.171      |\n","|    n_updates            | 3085        |\n","|    policy_gradient_loss | -0.00522    |\n","|    value_loss           | 0.0416      |\n","-----------------------------------------\n","Eval num_timesteps=2528000, episode_reward=0.40 +/- 0.49\n","Episode length: 172.00 +/- 16.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 172          |\n","|    mean_reward          | 0.4          |\n","| time/                   |              |\n","|    total_timesteps      | 2528000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0129114855 |\n","|    clip_fraction        | 0.0432       |\n","|    clip_range           | 0.3          |\n","|    entropy_loss         | -1.76        |\n","|    explained_variance   | 0.212        |\n","|    learning_rate        | 0.000622     |\n","|    loss                 | -0.142       |\n","|    n_updates            | 3090         |\n","|    policy_gradient_loss | -0.00644     |\n","|    value_loss           | 0.0464       |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 309     |\n","|    time_elapsed    | 7024    |\n","|    total_timesteps | 2531328 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 360         |\n","|    iterations           | 310         |\n","|    time_elapsed         | 7040        |\n","|    total_timesteps      | 2539520     |\n","| train/                  |             |\n","|    approx_kl            | 0.014280828 |\n","|    clip_fraction        | 0.0455      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.218       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.16       |\n","|    n_updates            | 3095        |\n","|    policy_gradient_loss | -0.00881    |\n","|    value_loss           | 0.0488      |\n","-----------------------------------------\n","Eval num_timesteps=2544000, episode_reward=0.40 +/- 0.49\n","Episode length: 184.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 184         |\n","|    mean_reward          | 0.4         |\n","| time/                   |             |\n","|    total_timesteps      | 2544000     |\n","| train/                  |             |\n","|    approx_kl            | 0.018577008 |\n","|    clip_fraction        | 0.0637      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.196       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.181      |\n","|    n_updates            | 3100        |\n","|    policy_gradient_loss | -0.00373    |\n","|    value_loss           | 0.047       |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 311     |\n","|    time_elapsed    | 7067    |\n","|    total_timesteps | 2547712 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 360         |\n","|    iterations           | 312         |\n","|    time_elapsed         | 7083        |\n","|    total_timesteps      | 2555904     |\n","| train/                  |             |\n","|    approx_kl            | 0.019441687 |\n","|    clip_fraction        | 0.0609      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.0734      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.183      |\n","|    n_updates            | 3105        |\n","|    policy_gradient_loss | -0.00797    |\n","|    value_loss           | 0.0478      |\n","-----------------------------------------\n","Eval num_timesteps=2560000, episode_reward=0.40 +/- 0.49\n","Episode length: 168.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 168         |\n","|    mean_reward          | 0.4         |\n","| time/                   |             |\n","|    total_timesteps      | 2560000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014853876 |\n","|    clip_fraction        | 0.0527      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.118       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.175      |\n","|    n_updates            | 3110        |\n","|    policy_gradient_loss | -0.00613    |\n","|    value_loss           | 0.0401      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 313     |\n","|    time_elapsed    | 7110    |\n","|    total_timesteps | 2564096 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 360         |\n","|    iterations           | 314         |\n","|    time_elapsed         | 7127        |\n","|    total_timesteps      | 2572288     |\n","| train/                  |             |\n","|    approx_kl            | 0.014731616 |\n","|    clip_fraction        | 0.0582      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.171       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.169      |\n","|    n_updates            | 3115        |\n","|    policy_gradient_loss | -0.00795    |\n","|    value_loss           | 0.0502      |\n","-----------------------------------------\n","Eval num_timesteps=2576000, episode_reward=0.40 +/- 0.49\n","Episode length: 176.00 +/- 24.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 176         |\n","|    mean_reward          | 0.4         |\n","| time/                   |             |\n","|    total_timesteps      | 2576000     |\n","| train/                  |             |\n","|    approx_kl            | 0.009514766 |\n","|    clip_fraction        | 0.0227      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.76       |\n","|    explained_variance   | 0.239       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.162      |\n","|    n_updates            | 3120        |\n","|    policy_gradient_loss | -0.00559    |\n","|    value_loss           | 0.0536      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 315     |\n","|    time_elapsed    | 7156    |\n","|    total_timesteps | 2580480 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 360         |\n","|    iterations           | 316         |\n","|    time_elapsed         | 7171        |\n","|    total_timesteps      | 2588672     |\n","| train/                  |             |\n","|    approx_kl            | 0.012760565 |\n","|    clip_fraction        | 0.0402      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.194       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.164      |\n","|    n_updates            | 3125        |\n","|    policy_gradient_loss | -0.00701    |\n","|    value_loss           | 0.0386      |\n","-----------------------------------------\n","Eval num_timesteps=2592000, episode_reward=0.80 +/- 0.98\n","Episode length: 188.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 188         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 2592000     |\n","| train/                  |             |\n","|    approx_kl            | 0.011900071 |\n","|    clip_fraction        | 0.0394      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.317       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.167      |\n","|    n_updates            | 3130        |\n","|    policy_gradient_loss | -0.00393    |\n","|    value_loss           | 0.0442      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 317     |\n","|    time_elapsed    | 7199    |\n","|    total_timesteps | 2596864 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 361         |\n","|    iterations           | 318         |\n","|    time_elapsed         | 7214        |\n","|    total_timesteps      | 2605056     |\n","| train/                  |             |\n","|    approx_kl            | 0.016402697 |\n","|    clip_fraction        | 0.0571      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.247       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.177      |\n","|    n_updates            | 3135        |\n","|    policy_gradient_loss | -0.00702    |\n","|    value_loss           | 0.0402      |\n","-----------------------------------------\n","Eval num_timesteps=2608000, episode_reward=0.60 +/- 1.20\n","Episode length: 196.00 +/- 24.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 196         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 2608000     |\n","| train/                  |             |\n","|    approx_kl            | 0.011202594 |\n","|    clip_fraction        | 0.0366      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.233       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.177      |\n","|    n_updates            | 3140        |\n","|    policy_gradient_loss | -0.00596    |\n","|    value_loss           | 0.0391      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 319     |\n","|    time_elapsed    | 7246    |\n","|    total_timesteps | 2613248 |\n","--------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 360        |\n","|    iterations           | 320        |\n","|    time_elapsed         | 7263       |\n","|    total_timesteps      | 2621440    |\n","| train/                  |            |\n","|    approx_kl            | 0.01001765 |\n","|    clip_fraction        | 0.0282     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.75      |\n","|    explained_variance   | 0.167      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.17      |\n","|    n_updates            | 3145       |\n","|    policy_gradient_loss | -0.00594   |\n","|    value_loss           | 0.0477     |\n","----------------------------------------\n","Eval num_timesteps=2624000, episode_reward=0.40 +/- 0.80\n","Episode length: 180.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 180         |\n","|    mean_reward          | 0.4         |\n","| time/                   |             |\n","|    total_timesteps      | 2624000     |\n","| train/                  |             |\n","|    approx_kl            | 0.015469161 |\n","|    clip_fraction        | 0.0514      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.107       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.16       |\n","|    n_updates            | 3150        |\n","|    policy_gradient_loss | -0.00891    |\n","|    value_loss           | 0.0488      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 321     |\n","|    time_elapsed    | 7292    |\n","|    total_timesteps | 2629632 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 360         |\n","|    iterations           | 322         |\n","|    time_elapsed         | 7310        |\n","|    total_timesteps      | 2637824     |\n","| train/                  |             |\n","|    approx_kl            | 0.011249861 |\n","|    clip_fraction        | 0.0372      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.161       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.146      |\n","|    n_updates            | 3155        |\n","|    policy_gradient_loss | -0.00788    |\n","|    value_loss           | 0.0383      |\n","-----------------------------------------\n","Eval num_timesteps=2640000, episode_reward=0.40 +/- 0.80\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0.4         |\n","| time/                   |             |\n","|    total_timesteps      | 2640000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014470628 |\n","|    clip_fraction        | 0.0418      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.216       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.144      |\n","|    n_updates            | 3160        |\n","|    policy_gradient_loss | -0.00935    |\n","|    value_loss           | 0.0458      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 323     |\n","|    time_elapsed    | 7337    |\n","|    total_timesteps | 2646016 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 360         |\n","|    iterations           | 324         |\n","|    time_elapsed         | 7354        |\n","|    total_timesteps      | 2654208     |\n","| train/                  |             |\n","|    approx_kl            | 0.013424261 |\n","|    clip_fraction        | 0.047       |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.137       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.182      |\n","|    n_updates            | 3165        |\n","|    policy_gradient_loss | -0.00633    |\n","|    value_loss           | 0.038       |\n","-----------------------------------------\n","Eval num_timesteps=2656000, episode_reward=0.60 +/- 0.80\n","Episode length: 192.00 +/- 16.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 192        |\n","|    mean_reward          | 0.6        |\n","| time/                   |            |\n","|    total_timesteps      | 2656000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01226816 |\n","|    clip_fraction        | 0.0361     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.74      |\n","|    explained_variance   | 0.204      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.153     |\n","|    n_updates            | 3170       |\n","|    policy_gradient_loss | -0.00882   |\n","|    value_loss           | 0.0397     |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 325     |\n","|    time_elapsed    | 7382    |\n","|    total_timesteps | 2662400 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 360         |\n","|    iterations           | 326         |\n","|    time_elapsed         | 7400        |\n","|    total_timesteps      | 2670592     |\n","| train/                  |             |\n","|    approx_kl            | 0.010499868 |\n","|    clip_fraction        | 0.0333      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.061       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.161      |\n","|    n_updates            | 3175        |\n","|    policy_gradient_loss | -0.00815    |\n","|    value_loss           | 0.0386      |\n","-----------------------------------------\n","Eval num_timesteps=2672000, episode_reward=0.40 +/- 0.80\n","Episode length: 168.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 168         |\n","|    mean_reward          | 0.4         |\n","| time/                   |             |\n","|    total_timesteps      | 2672000     |\n","| train/                  |             |\n","|    approx_kl            | 0.012333121 |\n","|    clip_fraction        | 0.0338      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.257       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.159      |\n","|    n_updates            | 3180        |\n","|    policy_gradient_loss | -0.00739    |\n","|    value_loss           | 0.0433      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 327     |\n","|    time_elapsed    | 7427    |\n","|    total_timesteps | 2678784 |\n","--------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 360       |\n","|    iterations           | 328       |\n","|    time_elapsed         | 7445      |\n","|    total_timesteps      | 2686976   |\n","| train/                  |           |\n","|    approx_kl            | 0.0152329 |\n","|    clip_fraction        | 0.035     |\n","|    clip_range           | 0.3       |\n","|    entropy_loss         | -1.75     |\n","|    explained_variance   | 0.297     |\n","|    learning_rate        | 0.000622  |\n","|    loss                 | -0.181    |\n","|    n_updates            | 3185      |\n","|    policy_gradient_loss | -0.00563  |\n","|    value_loss           | 0.0398    |\n","---------------------------------------\n","Eval num_timesteps=2688000, episode_reward=0.80 +/- 0.98\n","Episode length: 260.00 +/- 72.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 260         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 2688000     |\n","| train/                  |             |\n","|    approx_kl            | 0.012442303 |\n","|    clip_fraction        | 0.0358      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.76       |\n","|    explained_variance   | 0.119       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.158      |\n","|    n_updates            | 3190        |\n","|    policy_gradient_loss | -0.00716    |\n","|    value_loss           | 0.0394      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 329     |\n","|    time_elapsed    | 7483    |\n","|    total_timesteps | 2695168 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 360         |\n","|    iterations           | 330         |\n","|    time_elapsed         | 7499        |\n","|    total_timesteps      | 2703360     |\n","| train/                  |             |\n","|    approx_kl            | 0.011182191 |\n","|    clip_fraction        | 0.0417      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.218       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.156      |\n","|    n_updates            | 3195        |\n","|    policy_gradient_loss | -0.00657    |\n","|    value_loss           | 0.0322      |\n","-----------------------------------------\n","Eval num_timesteps=2704000, episode_reward=0.40 +/- 0.49\n","Episode length: 180.00 +/- 32.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 180          |\n","|    mean_reward          | 0.4          |\n","| time/                   |              |\n","|    total_timesteps      | 2704000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0120607065 |\n","|    clip_fraction        | 0.0363       |\n","|    clip_range           | 0.3          |\n","|    entropy_loss         | -1.74        |\n","|    explained_variance   | 0.169        |\n","|    learning_rate        | 0.000622     |\n","|    loss                 | -0.174       |\n","|    n_updates            | 3200         |\n","|    policy_gradient_loss | -0.0071      |\n","|    value_loss           | 0.0429       |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 360     |\n","|    iterations      | 331     |\n","|    time_elapsed    | 7532    |\n","|    total_timesteps | 2711552 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 360         |\n","|    iterations           | 332         |\n","|    time_elapsed         | 7547        |\n","|    total_timesteps      | 2719744     |\n","| train/                  |             |\n","|    approx_kl            | 0.011431871 |\n","|    clip_fraction        | 0.0407      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.0749      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.148      |\n","|    n_updates            | 3205        |\n","|    policy_gradient_loss | -0.00786    |\n","|    value_loss           | 0.0344      |\n","-----------------------------------------\n","Eval num_timesteps=2720000, episode_reward=2.00 +/- 2.76\n","Episode length: 260.00 +/- 48.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 260         |\n","|    mean_reward          | 2           |\n","| time/                   |             |\n","|    total_timesteps      | 2720000     |\n","| train/                  |             |\n","|    approx_kl            | 0.013281992 |\n","|    clip_fraction        | 0.0413      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.225       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.16       |\n","|    n_updates            | 3210        |\n","|    policy_gradient_loss | -0.0081     |\n","|    value_loss           | 0.0416      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 333     |\n","|    time_elapsed    | 7581    |\n","|    total_timesteps | 2727936 |\n","--------------------------------\n","Eval num_timesteps=2736000, episode_reward=0.60 +/- 1.20\n","Episode length: 204.00 +/- 40.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 204        |\n","|    mean_reward          | 0.6        |\n","| time/                   |            |\n","|    total_timesteps      | 2736000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01586161 |\n","|    clip_fraction        | 0.0487     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.73      |\n","|    explained_variance   | 0.172      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.159     |\n","|    n_updates            | 3215       |\n","|    policy_gradient_loss | -0.00576   |\n","|    value_loss           | 0.0518     |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 334     |\n","|    time_elapsed    | 7613    |\n","|    total_timesteps | 2736128 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 359         |\n","|    iterations           | 335         |\n","|    time_elapsed         | 7630        |\n","|    total_timesteps      | 2744320     |\n","| train/                  |             |\n","|    approx_kl            | 0.016857615 |\n","|    clip_fraction        | 0.0489      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.226       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.175      |\n","|    n_updates            | 3220        |\n","|    policy_gradient_loss | -0.00892    |\n","|    value_loss           | 0.0444      |\n","-----------------------------------------\n","Eval num_timesteps=2752000, episode_reward=0.80 +/- 0.75\n","Episode length: 184.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 184         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 2752000     |\n","| train/                  |             |\n","|    approx_kl            | 0.011048449 |\n","|    clip_fraction        | 0.0286      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.132       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.18       |\n","|    n_updates            | 3225        |\n","|    policy_gradient_loss | -0.00446    |\n","|    value_loss           | 0.0467      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 336     |\n","|    time_elapsed    | 7657    |\n","|    total_timesteps | 2752512 |\n","--------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 359        |\n","|    iterations           | 337        |\n","|    time_elapsed         | 7674       |\n","|    total_timesteps      | 2760704    |\n","| train/                  |            |\n","|    approx_kl            | 0.01470674 |\n","|    clip_fraction        | 0.0454     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.73      |\n","|    explained_variance   | 0.155      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.158     |\n","|    n_updates            | 3230       |\n","|    policy_gradient_loss | -0.0094    |\n","|    value_loss           | 0.0458     |\n","----------------------------------------\n","Eval num_timesteps=2768000, episode_reward=1.20 +/- 1.17\n","Episode length: 188.00 +/- 8.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 188        |\n","|    mean_reward          | 1.2        |\n","| time/                   |            |\n","|    total_timesteps      | 2768000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01185238 |\n","|    clip_fraction        | 0.0445     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.72      |\n","|    explained_variance   | 0.307      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.175     |\n","|    n_updates            | 3235       |\n","|    policy_gradient_loss | -0.00909   |\n","|    value_loss           | 0.0427     |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 338     |\n","|    time_elapsed    | 7704    |\n","|    total_timesteps | 2768896 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 359         |\n","|    iterations           | 339         |\n","|    time_elapsed         | 7719        |\n","|    total_timesteps      | 2777088     |\n","| train/                  |             |\n","|    approx_kl            | 0.015310733 |\n","|    clip_fraction        | 0.04        |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | -0.0137     |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.166      |\n","|    n_updates            | 3240        |\n","|    policy_gradient_loss | -0.0061     |\n","|    value_loss           | 0.0383      |\n","-----------------------------------------\n","Eval num_timesteps=2784000, episode_reward=0.80 +/- 0.98\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 2784000     |\n","| train/                  |             |\n","|    approx_kl            | 0.010789117 |\n","|    clip_fraction        | 0.0289      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.24        |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.165      |\n","|    n_updates            | 3245        |\n","|    policy_gradient_loss | -0.00764    |\n","|    value_loss           | 0.0424      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 340     |\n","|    time_elapsed    | 7747    |\n","|    total_timesteps | 2785280 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 359         |\n","|    iterations           | 341         |\n","|    time_elapsed         | 7762        |\n","|    total_timesteps      | 2793472     |\n","| train/                  |             |\n","|    approx_kl            | 0.012287484 |\n","|    clip_fraction        | 0.05        |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.139       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.167      |\n","|    n_updates            | 3250        |\n","|    policy_gradient_loss | -0.00718    |\n","|    value_loss           | 0.04        |\n","-----------------------------------------\n","Eval num_timesteps=2800000, episode_reward=0.60 +/- 1.20\n","Episode length: 172.00 +/- 16.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 172         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 2800000     |\n","| train/                  |             |\n","|    approx_kl            | 0.017506462 |\n","|    clip_fraction        | 0.0676      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.171       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.164      |\n","|    n_updates            | 3255        |\n","|    policy_gradient_loss | -0.0122     |\n","|    value_loss           | 0.0387      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 342     |\n","|    time_elapsed    | 7791    |\n","|    total_timesteps | 2801664 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 359         |\n","|    iterations           | 343         |\n","|    time_elapsed         | 7807        |\n","|    total_timesteps      | 2809856     |\n","| train/                  |             |\n","|    approx_kl            | 0.012515514 |\n","|    clip_fraction        | 0.0531      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.272       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.176      |\n","|    n_updates            | 3260        |\n","|    policy_gradient_loss | -0.00617    |\n","|    value_loss           | 0.0395      |\n","-----------------------------------------\n","Eval num_timesteps=2816000, episode_reward=0.80 +/- 1.17\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0.8         |\n","| time/                   |             |\n","|    total_timesteps      | 2816000     |\n","| train/                  |             |\n","|    approx_kl            | 0.015183878 |\n","|    clip_fraction        | 0.0533      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.253       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.175      |\n","|    n_updates            | 3265        |\n","|    policy_gradient_loss | -0.00974    |\n","|    value_loss           | 0.0465      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 344     |\n","|    time_elapsed    | 7834    |\n","|    total_timesteps | 2818048 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 360         |\n","|    iterations           | 345         |\n","|    time_elapsed         | 7849        |\n","|    total_timesteps      | 2826240     |\n","| train/                  |             |\n","|    approx_kl            | 0.014033503 |\n","|    clip_fraction        | 0.0507      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.12        |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.149      |\n","|    n_updates            | 3270        |\n","|    policy_gradient_loss | -0.00573    |\n","|    value_loss           | 0.039       |\n","-----------------------------------------\n","Eval num_timesteps=2832000, episode_reward=0.60 +/- 0.80\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 2832000     |\n","| train/                  |             |\n","|    approx_kl            | 0.018624704 |\n","|    clip_fraction        | 0.0577      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.173       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.17       |\n","|    n_updates            | 3275        |\n","|    policy_gradient_loss | -0.00796    |\n","|    value_loss           | 0.0397      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 346     |\n","|    time_elapsed    | 7876    |\n","|    total_timesteps | 2834432 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 360         |\n","|    iterations           | 347         |\n","|    time_elapsed         | 7892        |\n","|    total_timesteps      | 2842624     |\n","| train/                  |             |\n","|    approx_kl            | 0.017057411 |\n","|    clip_fraction        | 0.0601      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.75       |\n","|    explained_variance   | 0.111       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.161      |\n","|    n_updates            | 3280        |\n","|    policy_gradient_loss | -0.0103     |\n","|    value_loss           | 0.0336      |\n","-----------------------------------------\n","Eval num_timesteps=2848000, episode_reward=1.00 +/- 1.55\n","Episode length: 228.00 +/- 8.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 228        |\n","|    mean_reward          | 1          |\n","| time/                   |            |\n","|    total_timesteps      | 2848000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01682105 |\n","|    clip_fraction        | 0.0628     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.73      |\n","|    explained_variance   | 0.193      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.186     |\n","|    n_updates            | 3285       |\n","|    policy_gradient_loss | -0.0136    |\n","|    value_loss           | 0.0426     |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 348     |\n","|    time_elapsed    | 7924    |\n","|    total_timesteps | 2850816 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 360         |\n","|    iterations           | 349         |\n","|    time_elapsed         | 7940        |\n","|    total_timesteps      | 2859008     |\n","| train/                  |             |\n","|    approx_kl            | 0.015680142 |\n","|    clip_fraction        | 0.0637      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.211       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.177      |\n","|    n_updates            | 3290        |\n","|    policy_gradient_loss | -0.0111     |\n","|    value_loss           | 0.0371      |\n","-----------------------------------------\n","Eval num_timesteps=2864000, episode_reward=0.60 +/- 0.80\n","Episode length: 192.00 +/- 16.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 192         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 2864000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014173715 |\n","|    clip_fraction        | 0.0447      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.287       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.143      |\n","|    n_updates            | 3295        |\n","|    policy_gradient_loss | -0.0107     |\n","|    value_loss           | 0.0422      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 350     |\n","|    time_elapsed    | 7971    |\n","|    total_timesteps | 2867200 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 359         |\n","|    iterations           | 351         |\n","|    time_elapsed         | 7989        |\n","|    total_timesteps      | 2875392     |\n","| train/                  |             |\n","|    approx_kl            | 0.012856798 |\n","|    clip_fraction        | 0.0476      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.185       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.167      |\n","|    n_updates            | 3300        |\n","|    policy_gradient_loss | -0.00895    |\n","|    value_loss           | 0.0425      |\n","-----------------------------------------\n","Eval num_timesteps=2880000, episode_reward=0.40 +/- 0.49\n","Episode length: 184.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 184         |\n","|    mean_reward          | 0.4         |\n","| time/                   |             |\n","|    total_timesteps      | 2880000     |\n","| train/                  |             |\n","|    approx_kl            | 0.011657482 |\n","|    clip_fraction        | 0.0369      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.163       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.162      |\n","|    n_updates            | 3305        |\n","|    policy_gradient_loss | -0.00988    |\n","|    value_loss           | 0.0428      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 352     |\n","|    time_elapsed    | 8018    |\n","|    total_timesteps | 2883584 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 359         |\n","|    iterations           | 353         |\n","|    time_elapsed         | 8037        |\n","|    total_timesteps      | 2891776     |\n","| train/                  |             |\n","|    approx_kl            | 0.017452179 |\n","|    clip_fraction        | 0.0534      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.25        |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.167      |\n","|    n_updates            | 3310        |\n","|    policy_gradient_loss | -0.00459    |\n","|    value_loss           | 0.0381      |\n","-----------------------------------------\n","Eval num_timesteps=2896000, episode_reward=0.60 +/- 1.20\n","Episode length: 180.00 +/- 8.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 180          |\n","|    mean_reward          | 0.6          |\n","| time/                   |              |\n","|    total_timesteps      | 2896000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0143585615 |\n","|    clip_fraction        | 0.058        |\n","|    clip_range           | 0.3          |\n","|    entropy_loss         | -1.75        |\n","|    explained_variance   | 0.199        |\n","|    learning_rate        | 0.000622     |\n","|    loss                 | -0.175       |\n","|    n_updates            | 3315         |\n","|    policy_gradient_loss | -0.00578     |\n","|    value_loss           | 0.0426       |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 354     |\n","|    time_elapsed    | 8065    |\n","|    total_timesteps | 2899968 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 359          |\n","|    iterations           | 355          |\n","|    time_elapsed         | 8083         |\n","|    total_timesteps      | 2908160      |\n","| train/                  |              |\n","|    approx_kl            | 0.0122703565 |\n","|    clip_fraction        | 0.0446       |\n","|    clip_range           | 0.3          |\n","|    entropy_loss         | -1.73        |\n","|    explained_variance   | 0.224        |\n","|    learning_rate        | 0.000622     |\n","|    loss                 | -0.175       |\n","|    n_updates            | 3320         |\n","|    policy_gradient_loss | -0.00931     |\n","|    value_loss           | 0.0475       |\n","------------------------------------------\n","Eval num_timesteps=2912000, episode_reward=0.40 +/- 0.49\n","Episode length: 164.00 +/- 0.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 164        |\n","|    mean_reward          | 0.4        |\n","| time/                   |            |\n","|    total_timesteps      | 2912000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01080511 |\n","|    clip_fraction        | 0.0371     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.73      |\n","|    explained_variance   | 0.171      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.186     |\n","|    n_updates            | 3325       |\n","|    policy_gradient_loss | -0.00902   |\n","|    value_loss           | 0.043      |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 356     |\n","|    time_elapsed    | 8109    |\n","|    total_timesteps | 2916352 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 359         |\n","|    iterations           | 357         |\n","|    time_elapsed         | 8127        |\n","|    total_timesteps      | 2924544     |\n","| train/                  |             |\n","|    approx_kl            | 0.014211953 |\n","|    clip_fraction        | 0.0461      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.142       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.165      |\n","|    n_updates            | 3330        |\n","|    policy_gradient_loss | -0.00786    |\n","|    value_loss           | 0.0468      |\n","-----------------------------------------\n","Eval num_timesteps=2928000, episode_reward=1.00 +/- 0.89\n","Episode length: 208.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 208         |\n","|    mean_reward          | 1           |\n","| time/                   |             |\n","|    total_timesteps      | 2928000     |\n","| train/                  |             |\n","|    approx_kl            | 0.015028319 |\n","|    clip_fraction        | 0.0558      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.315       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.164      |\n","|    n_updates            | 3335        |\n","|    policy_gradient_loss | -0.00641    |\n","|    value_loss           | 0.0505      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 358     |\n","|    time_elapsed    | 8155    |\n","|    total_timesteps | 2932736 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 359         |\n","|    iterations           | 359         |\n","|    time_elapsed         | 8174        |\n","|    total_timesteps      | 2940928     |\n","| train/                  |             |\n","|    approx_kl            | 0.013597008 |\n","|    clip_fraction        | 0.0539      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.104       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.167      |\n","|    n_updates            | 3340        |\n","|    policy_gradient_loss | -0.00915    |\n","|    value_loss           | 0.0418      |\n","-----------------------------------------\n","Eval num_timesteps=2944000, episode_reward=1.00 +/- 1.55\n","Episode length: 164.00 +/- 0.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 164        |\n","|    mean_reward          | 1          |\n","| time/                   |            |\n","|    total_timesteps      | 2944000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01569389 |\n","|    clip_fraction        | 0.0577     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.74      |\n","|    explained_variance   | 0.272      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.16      |\n","|    n_updates            | 3345       |\n","|    policy_gradient_loss | -0.00836   |\n","|    value_loss           | 0.042      |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 360     |\n","|    time_elapsed    | 8198    |\n","|    total_timesteps | 2949120 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 359         |\n","|    iterations           | 361         |\n","|    time_elapsed         | 8217        |\n","|    total_timesteps      | 2957312     |\n","| train/                  |             |\n","|    approx_kl            | 0.017422235 |\n","|    clip_fraction        | 0.0593      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.148       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.149      |\n","|    n_updates            | 3350        |\n","|    policy_gradient_loss | -0.00611    |\n","|    value_loss           | 0.0377      |\n","-----------------------------------------\n","Eval num_timesteps=2960000, episode_reward=0.00 +/- 0.00\n","Episode length: 168.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 168         |\n","|    mean_reward          | 0           |\n","| time/                   |             |\n","|    total_timesteps      | 2960000     |\n","| train/                  |             |\n","|    approx_kl            | 0.013703807 |\n","|    clip_fraction        | 0.0654      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.218       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.147      |\n","|    n_updates            | 3355        |\n","|    policy_gradient_loss | -0.0105     |\n","|    value_loss           | 0.0416      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 362     |\n","|    time_elapsed    | 8248    |\n","|    total_timesteps | 2965504 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 359         |\n","|    iterations           | 363         |\n","|    time_elapsed         | 8265        |\n","|    total_timesteps      | 2973696     |\n","| train/                  |             |\n","|    approx_kl            | 0.012616452 |\n","|    clip_fraction        | 0.0351      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.258       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.168      |\n","|    n_updates            | 3360        |\n","|    policy_gradient_loss | -0.00765    |\n","|    value_loss           | 0.0418      |\n","-----------------------------------------\n","Eval num_timesteps=2976000, episode_reward=0.40 +/- 0.80\n","Episode length: 164.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 164         |\n","|    mean_reward          | 0.4         |\n","| time/                   |             |\n","|    total_timesteps      | 2976000     |\n","| train/                  |             |\n","|    approx_kl            | 0.012433151 |\n","|    clip_fraction        | 0.0415      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.221       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.158      |\n","|    n_updates            | 3365        |\n","|    policy_gradient_loss | -0.00813    |\n","|    value_loss           | 0.0465      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 364     |\n","|    time_elapsed    | 8290    |\n","|    total_timesteps | 2981888 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 359         |\n","|    iterations           | 365         |\n","|    time_elapsed         | 8308        |\n","|    total_timesteps      | 2990080     |\n","| train/                  |             |\n","|    approx_kl            | 0.017168682 |\n","|    clip_fraction        | 0.0643      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.155       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.167      |\n","|    n_updates            | 3370        |\n","|    policy_gradient_loss | -0.00826    |\n","|    value_loss           | 0.0379      |\n","-----------------------------------------\n","Eval num_timesteps=2992000, episode_reward=0.60 +/- 0.80\n","Episode length: 172.00 +/- 16.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 172         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 2992000     |\n","| train/                  |             |\n","|    approx_kl            | 0.012826486 |\n","|    clip_fraction        | 0.042       |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.118       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.187      |\n","|    n_updates            | 3375        |\n","|    policy_gradient_loss | -0.00844    |\n","|    value_loss           | 0.042       |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 366     |\n","|    time_elapsed    | 8335    |\n","|    total_timesteps | 2998272 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 359         |\n","|    iterations           | 367         |\n","|    time_elapsed         | 8352        |\n","|    total_timesteps      | 3006464     |\n","| train/                  |             |\n","|    approx_kl            | 0.016133092 |\n","|    clip_fraction        | 0.0631      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.316       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.179      |\n","|    n_updates            | 3380        |\n","|    policy_gradient_loss | -0.01       |\n","|    value_loss           | 0.0415      |\n","-----------------------------------------\n","Eval num_timesteps=3008000, episode_reward=1.60 +/- 2.33\n","Episode length: 248.00 +/- 32.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 248         |\n","|    mean_reward          | 1.6         |\n","| time/                   |             |\n","|    total_timesteps      | 3008000     |\n","| train/                  |             |\n","|    approx_kl            | 0.017442543 |\n","|    clip_fraction        | 0.0482      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.71       |\n","|    explained_variance   | 0.168       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.192      |\n","|    n_updates            | 3385        |\n","|    policy_gradient_loss | -0.00958    |\n","|    value_loss           | 0.0456      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 368     |\n","|    time_elapsed    | 8384    |\n","|    total_timesteps | 3014656 |\n","--------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 359        |\n","|    iterations           | 369        |\n","|    time_elapsed         | 8400       |\n","|    total_timesteps      | 3022848    |\n","| train/                  |            |\n","|    approx_kl            | 0.01841176 |\n","|    clip_fraction        | 0.0663     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.7       |\n","|    explained_variance   | 0.221      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.169     |\n","|    n_updates            | 3390       |\n","|    policy_gradient_loss | -0.0107    |\n","|    value_loss           | 0.0394     |\n","----------------------------------------\n","Eval num_timesteps=3024000, episode_reward=0.40 +/- 0.49\n","Episode length: 164.00 +/- 0.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 164        |\n","|    mean_reward          | 0.4        |\n","| time/                   |            |\n","|    total_timesteps      | 3024000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01746618 |\n","|    clip_fraction        | 0.063      |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.71      |\n","|    explained_variance   | 0.25       |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.179     |\n","|    n_updates            | 3395       |\n","|    policy_gradient_loss | -0.00932   |\n","|    value_loss           | 0.0499     |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 370     |\n","|    time_elapsed    | 8426    |\n","|    total_timesteps | 3031040 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 359         |\n","|    iterations           | 371         |\n","|    time_elapsed         | 8442        |\n","|    total_timesteps      | 3039232     |\n","| train/                  |             |\n","|    approx_kl            | 0.013277687 |\n","|    clip_fraction        | 0.037       |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.71       |\n","|    explained_variance   | 0.167       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.175      |\n","|    n_updates            | 3400        |\n","|    policy_gradient_loss | -0.0103     |\n","|    value_loss           | 0.0411      |\n","-----------------------------------------\n","Eval num_timesteps=3040000, episode_reward=1.00 +/- 0.63\n","Episode length: 188.00 +/- 8.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 188         |\n","|    mean_reward          | 1           |\n","| time/                   |             |\n","|    total_timesteps      | 3040000     |\n","| train/                  |             |\n","|    approx_kl            | 0.015259154 |\n","|    clip_fraction        | 0.057       |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.167       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.176      |\n","|    n_updates            | 3405        |\n","|    policy_gradient_loss | -0.0075     |\n","|    value_loss           | 0.0449      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 372     |\n","|    time_elapsed    | 8471    |\n","|    total_timesteps | 3047424 |\n","--------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 360        |\n","|    iterations           | 373        |\n","|    time_elapsed         | 8487       |\n","|    total_timesteps      | 3055616    |\n","| train/                  |            |\n","|    approx_kl            | 0.01137227 |\n","|    clip_fraction        | 0.0411     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.73      |\n","|    explained_variance   | 0.131      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.155     |\n","|    n_updates            | 3410       |\n","|    policy_gradient_loss | -0.00505   |\n","|    value_loss           | 0.0393     |\n","----------------------------------------\n","Eval num_timesteps=3056000, episode_reward=0.20 +/- 0.40\n","Episode length: 172.00 +/- 16.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 172         |\n","|    mean_reward          | 0.2         |\n","| time/                   |             |\n","|    total_timesteps      | 3056000     |\n","| train/                  |             |\n","|    approx_kl            | 0.014028322 |\n","|    clip_fraction        | 0.0465      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.26        |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.17       |\n","|    n_updates            | 3415        |\n","|    policy_gradient_loss | -0.00639    |\n","|    value_loss           | 0.0392      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 374     |\n","|    time_elapsed    | 8515    |\n","|    total_timesteps | 3063808 |\n","--------------------------------\n","Eval num_timesteps=3072000, episode_reward=0.60 +/- 0.80\n","Episode length: 164.00 +/- 0.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 164        |\n","|    mean_reward          | 0.6        |\n","| time/                   |            |\n","|    total_timesteps      | 3072000    |\n","| train/                  |            |\n","|    approx_kl            | 0.01575955 |\n","|    clip_fraction        | 0.0488     |\n","|    clip_range           | 0.3        |\n","|    entropy_loss         | -1.73      |\n","|    explained_variance   | 0.173      |\n","|    learning_rate        | 0.000622   |\n","|    loss                 | -0.173     |\n","|    n_updates            | 3420       |\n","|    policy_gradient_loss | -0.00984   |\n","|    value_loss           | 0.0379     |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 375     |\n","|    time_elapsed    | 8544    |\n","|    total_timesteps | 3072000 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 359         |\n","|    iterations           | 376         |\n","|    time_elapsed         | 8560        |\n","|    total_timesteps      | 3080192     |\n","| train/                  |             |\n","|    approx_kl            | 0.014526657 |\n","|    clip_fraction        | 0.0491      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.72       |\n","|    explained_variance   | 0.134       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.164      |\n","|    n_updates            | 3425        |\n","|    policy_gradient_loss | -0.00972    |\n","|    value_loss           | 0.0453      |\n","-----------------------------------------\n","Eval num_timesteps=3088000, episode_reward=0.60 +/- 1.20\n","Episode length: 204.00 +/- 40.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 204         |\n","|    mean_reward          | 0.6         |\n","| time/                   |             |\n","|    total_timesteps      | 3088000     |\n","| train/                  |             |\n","|    approx_kl            | 0.017137827 |\n","|    clip_fraction        | 0.0489      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.74       |\n","|    explained_variance   | 0.0917      |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.15       |\n","|    n_updates            | 3430        |\n","|    policy_gradient_loss | -0.00742    |\n","|    value_loss           | 0.0336      |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 359     |\n","|    iterations      | 377     |\n","|    time_elapsed    | 8593    |\n","|    total_timesteps | 3088384 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 359         |\n","|    iterations           | 378         |\n","|    time_elapsed         | 8611        |\n","|    total_timesteps      | 3096576     |\n","| train/                  |             |\n","|    approx_kl            | 0.013172908 |\n","|    clip_fraction        | 0.0494      |\n","|    clip_range           | 0.3         |\n","|    entropy_loss         | -1.73       |\n","|    explained_variance   | 0.285       |\n","|    learning_rate        | 0.000622    |\n","|    loss                 | -0.17       |\n","|    n_updates            | 3435        |\n","|    policy_gradient_loss | -0.00829    |\n","|    value_loss           | 0.036       |\n","-----------------------------------------\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1tshRK0UXCNEVBrB-ASJr3txhtNAtqktf","authorship_tag":"ABX9TyMwwFKSFZAthK4qHe6kP/Ne"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}