{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EvaluaciÃ³n en 10 partidas de los modelos de multiwalker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\v_ic_\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "c:\\Users\\v_ic_\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
            "c:\\Users\\v_ic_\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3.ppo import CnnPolicy, MlpPolicy, MultiInputPolicy\n",
        "from stable_baselines3 import PPO, DDPG, SAC\n",
        "from pettingzoo.sisl import multiwalker_v9\n",
        "import supersuit as ss\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def evalua_10_partidas(algoritmo,best_model):\n",
        "    env = multiwalker_v9.env(render_mode=None)\n",
        "    env = ss.frame_stack_v1(env, 3)\n",
        "\n",
        "    if algoritmo=='PPO':\n",
        "        model = PPO.load(best_model)\n",
        "    if algoritmo=='SAC':\n",
        "        model = SAC.load(best_model)\n",
        "    if algoritmo=='DDPG':\n",
        "        model = DDPG.load(best_model)\n",
        "    rewards = {agent: 0 for agent in env.possible_agents}\n",
        "\n",
        "    num_games=10\n",
        "\n",
        "    for i in range(num_games):\n",
        "        print(\"juego \",i)\n",
        "        env.reset(seed=i)\n",
        "        env.action_space(env.possible_agents[0]).seed(i)\n",
        "        # env.reset()\n",
        "        for agent in env.agent_iter():\n",
        "            obs, reward, done, info,_ = env.last()\n",
        "            # if reward>=1:\n",
        "            #     print(reward>=1)\n",
        "            for agent in env.agents:\n",
        "                    rewards[agent] += env.rewards[agent]\n",
        "            # if reward >= 1:\n",
        "            #         print(\"Rewards agentes: \",rewards)\n",
        "            act = model.predict(obs, deterministic=True)[0] if not done else None\n",
        "            env.step(act)\n",
        "            # env.render()\n",
        "\n",
        "    env.close()\n",
        "    print(\"Recompensas totales: \", rewards)\n",
        "    print(\"Recompensas medias por juego: \")\n",
        "    for key,val in rewards.items():\n",
        "        total = val/num_games\n",
        "        print(total,key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DDPG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': 73.43401209947956, 'walker_1': 73.43401209947956, 'walker_2': 73.43401209947956}\n",
            "Recompensas medias por juego: \n",
            "7.343401209947956 walker_0\n",
            "7.343401209947956 walker_1\n",
            "7.343401209947956 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('DDPG',\"./multiwalker/results/multiwalker_ddpg2_5_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': -46.39672545654074, 'walker_1': -46.39672545654074, 'walker_2': -46.39672545654074}\n",
            "Recompensas medias por juego: \n",
            "-4.639672545654074 walker_0\n",
            "-4.639672545654074 walker_1\n",
            "-4.639672545654074 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('PPO',\"./multiwalker/results/multiwalker_ppo_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': 473.94370371566947, 'walker_1': 473.94370371566947, 'walker_2': 473.94370371566947}\n",
            "Recompensas medias por juego: \n",
            "47.39437037156695 walker_0\n",
            "47.39437037156695 walker_1\n",
            "47.39437037156695 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('PPO',\"./multiwalker/results/multiwalker_ppo_2_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': 58.68128625272458, 'walker_1': 58.68128625272458, 'walker_2': 58.68128625272458}\n",
            "Recompensas medias por juego: \n",
            "5.868128625272458 walker_0\n",
            "5.868128625272458 walker_1\n",
            "5.868128625272458 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('PPO',\"./multiwalker/results/multiwalker_ppo_rew_08_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': 321.42622547169856, 'walker_1': 321.42622547169856, 'walker_2': 321.42622547169856}\n",
            "Recompensas medias por juego: \n",
            "32.14262254716986 walker_0\n",
            "32.14262254716986 walker_1\n",
            "32.14262254716986 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('PPO',\"./multiwalker/results/multiwalker_ppo_08_2_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': 337.75941248486447, 'walker_1': 337.75941248486447, 'walker_2': 337.75941248486447}\n",
            "Recompensas medias por juego: \n",
            "33.77594124848645 walker_0\n",
            "33.77594124848645 walker_1\n",
            "33.77594124848645 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('PPO',\"./multiwalker/results/multiwalker_ppo_rew_04_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': 474.27291190127585, 'walker_1': 474.27291190127585, 'walker_2': 474.27291190127585}\n",
            "Recompensas medias por juego: \n",
            "47.42729119012758 walker_0\n",
            "47.42729119012758 walker_1\n",
            "47.42729119012758 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('PPO',\"./multiwalker/results/multiwalker_ppo_04_2_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': 248.26154586890087, 'walker_1': 248.26154586890087, 'walker_2': 248.26154586890087}\n",
            "Recompensas medias por juego: \n",
            "24.826154586890087 walker_0\n",
            "24.826154586890087 walker_1\n",
            "24.826154586890087 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('PPO',\"./multiwalker/results/multiwalker_ppo_rew_0_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': 79.45177246162216, 'walker_1': 79.45177246162216, 'walker_2': 79.45177246162216}\n",
            "Recompensas medias por juego: \n",
            "7.945177246162215 walker_0\n",
            "7.945177246162215 walker_1\n",
            "7.945177246162215 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('PPO',\"./multiwalker/results/multiwalker_ppo_0_2_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': -140.380159902886, 'walker_1': -140.380159902886, 'walker_2': -140.380159902886}\n",
            "Recompensas medias por juego: \n",
            "-14.0380159902886 walker_0\n",
            "-14.0380159902886 walker_1\n",
            "-14.0380159902886 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('SAC',\"./multiwalker/results/multiwalker_sac_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': 29.751287458464486, 'walker_1': 29.751287458464486, 'walker_2': 29.751287458464486}\n",
            "Recompensas medias por juego: \n",
            "2.9751287458464484 walker_0\n",
            "2.9751287458464484 walker_1\n",
            "2.9751287458464484 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('SAC',\"./multiwalker/results/multiwalker_sac_08_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': -546.9559073171885, 'walker_1': -546.9559073171885, 'walker_2': -546.9559073171885}\n",
            "Recompensas medias por juego: \n",
            "-54.695590731718845 walker_0\n",
            "-54.695590731718845 walker_1\n",
            "-54.695590731718845 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('SAC',\"./multiwalker/results/multiwalker_sac_04_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': 1265.6677896506499, 'walker_1': 1265.6677896506499, 'walker_2': 1265.6677896506499}\n",
            "Recompensas medias por juego: \n",
            "126.56677896506498 walker_0\n",
            "126.56677896506498 walker_1\n",
            "126.56677896506498 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('SAC',\"./multiwalker/results/multiwalker_sac_00_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': 539.7872102178309, 'walker_1': 539.7872102178309, 'walker_2': 539.7872102178309}\n",
            "Recompensas medias por juego: \n",
            "53.97872102178309 walker_0\n",
            "53.97872102178309 walker_1\n",
            "53.97872102178309 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('SAC',\"./multiwalker/results/multiwalker_sac2_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': 249.50671489466902, 'walker_1': 249.50671489466902, 'walker_2': 249.50671489466902}\n",
            "Recompensas medias por juego: \n",
            "24.950671489466902 walker_0\n",
            "24.950671489466902 walker_1\n",
            "24.950671489466902 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('SAC',\"./multiwalker/results/multiwalker_sac2_08_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': -157.08334282195847, 'walker_1': -157.08334282195847, 'walker_2': -157.08334282195847}\n",
            "Recompensas medias por juego: \n",
            "-15.708334282195846 walker_0\n",
            "-15.708334282195846 walker_1\n",
            "-15.708334282195846 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('SAC',\"./multiwalker/results/multiwalker_sac2_04_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': -393.6446195561447, 'walker_1': -393.6446195561447, 'walker_2': -393.6446195561447}\n",
            "Recompensas medias por juego: \n",
            "-39.364461955614466 walker_0\n",
            "-39.364461955614466 walker_1\n",
            "-39.364461955614466 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('SAC',\"./multiwalker/results/multiwalker_sac2_00_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': -114.63144091268353, 'walker_1': -114.63144091268353, 'walker_2': -114.63144091268353}\n",
            "Recompensas medias por juego: \n",
            "-11.463144091268353 walker_0\n",
            "-11.463144091268353 walker_1\n",
            "-11.463144091268353 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('SAC',\"./multiwalker/results/multiwalker_sac3_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': -1052.9148516977828, 'walker_1': -1052.9148516977828, 'walker_2': -1052.9148516977828}\n",
            "Recompensas medias por juego: \n",
            "-105.29148516977827 walker_0\n",
            "-105.29148516977827 walker_1\n",
            "-105.29148516977827 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('SAC',\"./multiwalker/results/multiwalker_sac3_08_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': -915.3695932058812, 'walker_1': -915.3695932058812, 'walker_2': -915.3695932058812}\n",
            "Recompensas medias por juego: \n",
            "-91.53695932058812 walker_0\n",
            "-91.53695932058812 walker_1\n",
            "-91.53695932058812 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('SAC',\"./multiwalker/results/multiwalker_sac3_04_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': -1011.009538714154, 'walker_1': -1011.009538714154, 'walker_2': -1011.009538714154}\n",
            "Recompensas medias por juego: \n",
            "-101.1009538714154 walker_0\n",
            "-101.1009538714154 walker_1\n",
            "-101.1009538714154 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('SAC',\"./multiwalker/results/multiwalker_sac3_00_log_eval/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "juego  0\n",
            "juego  1\n",
            "juego  2\n",
            "juego  3\n",
            "juego  4\n",
            "juego  5\n",
            "juego  6\n",
            "juego  7\n",
            "juego  8\n",
            "juego  9\n",
            "Recompensas totales:  {'walker_0': 1352.261099606755, 'walker_1': 1352.261099606755, 'walker_2': 1352.261099606755}\n",
            "Recompensas medias por juego: \n",
            "135.2261099606755 walker_0\n",
            "135.2261099606755 walker_1\n",
            "135.2261099606755 walker_2\n"
          ]
        }
      ],
      "source": [
        "evalua_10_partidas('SAC',\"./multiwalker/results/multiwalker_sac_00_log_eval_extra2/best_model\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
